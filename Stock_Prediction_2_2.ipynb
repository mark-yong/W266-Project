{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Softmax\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "maxlen=20\n",
    "embedding_dim = 100\n",
    "text_vocabulary_size = 140000\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v =Word2Vec.load('w2v.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_pickle('train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate word_indices with embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and fit on text\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_matrix = np.zeros((text_vocabulary_size, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a weight matrix for words in training docs\n",
    "for word, i in t.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = w2v.wv.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, ['news_title']] = train_df.loc[:, ['news_title']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "train_df['words'] = train_df.news_title.map(simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to sequence\n",
    "train_df['embeddings'] = t.texts_to_sequences(train_df['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "train_embed = pad_sequences(train_df['embeddings'], maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>news_title</th>\n",
       "      <th>source</th>\n",
       "      <th>stock</th>\n",
       "      <th>words</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:16:16-04:00</td>\n",
       "      <td>Inco's Net Soars on Higher Metal Prices, Break...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[inco, net, soars, on, higher, metal, prices, ...</td>\n",
       "      <td>[4185, 1198, 8081, 86, 373, 7597, 418, 20386, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:25:00-04:00</td>\n",
       "      <td>Hey buddy, can you spare $600 for a Google sha...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, buddy, can, you, spare, for, google, share]</td>\n",
       "      <td>[266, 267, 182, 268, 269, 80, 270, 271]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 18:15:00-04:00</td>\n",
       "      <td>Exxon Mobil offers plan to end Alaska dispute.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[exxon, mobil, offers, plan, to, end, alaska, ...</td>\n",
       "      <td>[31, 32, 33, 34, 35, 36, 37, 38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 20:08:44-04:00</td>\n",
       "      <td>Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[jim, cramer, diageo, anheuser, busch, monster...</td>\n",
       "      <td>[2243, 12399, 31064, 4988, 4989, 7611, 1391, 270]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-21 14:21:00-04:00</td>\n",
       "      <td>AOL CEO says sales may shrink for two years -p...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[aol, ceo, says, sales, may, shrink, for, two,...</td>\n",
       "      <td>[535, 536, 537, 538, 361, 539, 80, 216, 134, 540]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-21 20:11:00-04:00</td>\n",
       "      <td>Pluspetrol says losing $2.4 mln/day in Peru pr...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[pluspetrol, says, losing, mln, day, in, peru,...</td>\n",
       "      <td>[885, 537, 175, 886, 887, 88, 888, 889]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 06:46:00-04:00</td>\n",
       "      <td>EU to urge China to open economy further.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[eu, to, urge, china, to, open, economy, further]</td>\n",
       "      <td>[943, 35, 944, 945, 35, 946, 693, 644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 12:14:00-04:00</td>\n",
       "      <td>Fed to keep hawkish tone, hold rates steady.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[fed, to, keep, hawkish, tone, hold, rates, st...</td>\n",
       "      <td>[683, 35, 684, 685, 686, 687, 688, 689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 20:36:00-04:00</td>\n",
       "      <td>Weatherford profit jumps 78 percent.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[weatherford, profit, jumps, percent]</td>\n",
       "      <td>[1186, 460, 1187, 310]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 21:51:00-04:00</td>\n",
       "      <td>Saudi Arabia tells Japan to cut its Nov crude ...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[saudi, arabia, tells, japan, to, cut, its, no...</td>\n",
       "      <td>[1944, 1945, 2006, 2007, 35, 822, 167, 2008, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 01:50:00-04:00</td>\n",
       "      <td>Australia's Foster's says confident on targets.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[australia, foster, says, confident, on, targets]</td>\n",
       "      <td>[1217, 1218, 537, 1219, 86, 289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 03:47:00-04:00</td>\n",
       "      <td>Macquarie bids $1.4 bln for metering firm Techem.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[macquarie, bids, bln, for, metering, firm, te...</td>\n",
       "      <td>[3031, 3032, 3033, 80, 3034, 657, 3035]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 03:51:00-04:00</td>\n",
       "      <td>DaimlerChrysler talks to 2 firms on small car:...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[daimlerchrysler, talks, to, firms, on, small,...</td>\n",
       "      <td>[1113, 663, 35, 1114, 86, 10, 1115, 540]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 05:24:00-04:00</td>\n",
       "      <td>More solid earnings may keep rally going.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[more, solid, earnings, may, keep, rally, going]</td>\n",
       "      <td>[162, 1756, 336, 361, 684, 1757, 787]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 07:51:36-04:00</td>\n",
       "      <td>EU Energy Chief Backs German Plan for Price Co...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[eu, energy, chief, backs, german, plan, for, ...</td>\n",
       "      <td>[943, 52, 554, 10553, 563, 34, 80, 288, 1405]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 08:36:00-04:00</td>\n",
       "      <td>U.S. venture investors betting on energy, Web ...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[venture, investors, betting, on, energy, web]</td>\n",
       "      <td>[2074, 501, 2075, 86, 52, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 09:58:00-04:00</td>\n",
       "      <td>Shell Canada jumps 30 pct on Royal Dutch offer.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[shell, canada, jumps, pct, on, royal, dutch, ...</td>\n",
       "      <td>[1889, 1206, 1187, 2027, 86, 1896, 1897, 110]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 10:47:00-04:00</td>\n",
       "      <td>Kimberly-Clark sees higher costs this year.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[kimberly, clark, sees, higher, costs, this, y...</td>\n",
       "      <td>[1795, 1796, 1751, 373, 1142, 92, 222]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 10:49:00-04:00</td>\n",
       "      <td>Ford won't sell Ford Credit.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, won, sell, ford, credit]</td>\n",
       "      <td>[1469, 1660, 678, 1469, 1604]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 10:56:00-04:00</td>\n",
       "      <td>Ford sees fourth quarter weaker than third.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, sees, fourth, quarter, weaker, than, th...</td>\n",
       "      <td>[1469, 1751, 1656, 497, 801, 163, 496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:18:00-04:00</td>\n",
       "      <td>Hasbro profit beats expectations.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[hasbro, profit, beats, expectations]</td>\n",
       "      <td>[2449, 460, 2450, 720]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:20:00-04:00</td>\n",
       "      <td>Merrill Lynch to buy Petrie Parkman.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[merrill, lynch, to, buy, petrie, parkman]</td>\n",
       "      <td>[344, 2203, 35, 649, 2204, 2205]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:41:00-04:00</td>\n",
       "      <td>Ford CEO: Jury out on European premium brands.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, ceo, jury, out, on, european, premium, ...</td>\n",
       "      <td>[1469, 536, 1622, 399, 86, 616, 1623, 1569]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:48:00-04:00</td>\n",
       "      <td>Kimberly-Clark profit higher, narrows view.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[kimberly, clark, profit, higher, narrows, view]</td>\n",
       "      <td>[1795, 1796, 460, 373, 2543, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:52:00-04:00</td>\n",
       "      <td>Wal-Mart October sales growth tracking below f...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[wal, mart, october, sales, growth, tracking, ...</td>\n",
       "      <td>[1293, 1294, 863, 538, 314, 2863, 1309, 795]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 12:34:00-04:00</td>\n",
       "      <td>Bombardier could launch new jet this year: ana...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[bombardier, could, launch, new, jet, this, ye...</td>\n",
       "      <td>[2978, 326, 1009, 180, 2979, 92, 222, 356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 14:10:00-04:00</td>\n",
       "      <td>Private equity groups form for Tribune bid: so...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[private, equity, groups, form, for, tribune, ...</td>\n",
       "      <td>[2754, 523, 929, 2755, 80, 2756, 672, 1176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 15:06:00-04:00</td>\n",
       "      <td>AT&amp;T earnings beat expectations.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[at, earnings, beat, expectations]</td>\n",
       "      <td>[515, 336, 1765, 720]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 15:40:00-04:00</td>\n",
       "      <td>Wrigley sees no change in communications policy.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[wrigley, sees, no, change, in, communications...</td>\n",
       "      <td>[2359, 1751, 206, 745, 88, 2360, 733]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 15:48:00-04:00</td>\n",
       "      <td>Ford is reviewing all products, brands: CEO.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, is, reviewing, all, products, brands, ceo]</td>\n",
       "      <td>[1469, 131, 1568, 177, 1164, 1569, 536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288185</th>\n",
       "      <td>288185</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:25:00-05:00</td>\n",
       "      <td>Mexico \"Buen Fin\" sales up by nearly a third.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[mexico, buen, fin, sales, up, by, nearly, third]</td>\n",
       "      <td>[2475, 84835, 8832, 538, 324, 39, 176, 496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288186</th>\n",
       "      <td>288186</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:16-05:00</td>\n",
       "      <td>Fed’s Dudley Signals a Shift Toward Bank Reform.</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[fed, dudley, signals, shift, toward, bank, re...</td>\n",
       "      <td>[683, 39510, 4488, 1093, 2552, 696, 1043]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288187</th>\n",
       "      <td>288187</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:17-05:00</td>\n",
       "      <td>Natural-Gas Exports Could Lift U.S. Trade and ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, gas, exports, could, lift, trade, an...</td>\n",
       "      <td>[95, 74, 988, 326, 2391, 363, 62, 693]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288188</th>\n",
       "      <td>288188</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:36-05:00</td>\n",
       "      <td>Spain’s Bad Bank Needs Goodwill From Europe’s ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[spain, bad, bank, needs, goodwill, from, euro...</td>\n",
       "      <td>[5372, 2178, 696, 968, 3372, 333, 662, 4149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288189</th>\n",
       "      <td>288189</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:58-05:00</td>\n",
       "      <td>Regulate U.S. Markets Like the Nuclear Industry.</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[regulate, markets, like, the, nuclear, industry]</td>\n",
       "      <td>[14044, 426, 316, 66, 3295, 645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288190</th>\n",
       "      <td>288190</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:44:00-05:00</td>\n",
       "      <td>Black Friday sales online top $1 billion for f...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[black, friday, sales, online, top, billion, f...</td>\n",
       "      <td>[9445, 87, 538, 604, 1443, 130, 80, 792, 403, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288191</th>\n",
       "      <td>288191</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:45:00-05:00</td>\n",
       "      <td>Apple seeks to add more products to Samsung pa...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[apple, seeks, to, add, more, products, to, sa...</td>\n",
       "      <td>[4307, 8803, 35, 1927, 162, 1164, 35, 6115, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288192</th>\n",
       "      <td>288192</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:52:54-05:00</td>\n",
       "      <td>Qantas Minds Bonds as Dreamliner Order Pulled:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[qantas, minds, bonds, as, dreamliner, order, ...</td>\n",
       "      <td>[15486, 2649, 4772, 106, 5403, 329, 5100, 1217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288193</th>\n",
       "      <td>288193</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:00:01-05:00</td>\n",
       "      <td>BBC’s Chief Honed Skills Saving Covent Garden:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[bbc, chief, honed, skills, saving, covent, ga...</td>\n",
       "      <td>[16611, 554, 25269, 15128, 4584, 85405, 11544,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288194</th>\n",
       "      <td>288194</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:00:01-05:00</td>\n",
       "      <td>White Burgundies From Cote d’Or Set Gold Stand...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[white, burgundies, from, cote, or, set, gold,...</td>\n",
       "      <td>[3279, 86934, 333, 24654, 334, 382, 8961, 1810]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288195</th>\n",
       "      <td>288195</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:00:01-05:00</td>\n",
       "      <td>Chelsea Ties 0-0 Against Man. City as Fans Jee...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[chelsea, ties, against, man, city, as, fans, ...</td>\n",
       "      <td>[7138, 1032, 1026, 2537, 1370, 106, 12710, 594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288196</th>\n",
       "      <td>288196</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>Britons’ Spending Power Stagnated in October o...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[britons, spending, power, stagnated, in, octo...</td>\n",
       "      <td>[29544, 1194, 1110, 22094, 88, 863, 86, 754, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288197</th>\n",
       "      <td>288197</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>U.K. Business Investment Seen at Pace Damping ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[business, investment, seen, at, pace, damping...</td>\n",
       "      <td>[480, 954, 1107, 515, 798, 38960, 962, 314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288198</th>\n",
       "      <td>288198</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>Colombia Bank Votes 4-3 for Rate Cut After Bro...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[colombia, bank, votes, for, rate, cut, after,...</td>\n",
       "      <td>[6648, 696, 2440, 80, 828, 822, 202, 5202, 24553]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288199</th>\n",
       "      <td>288199</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>U.K. Energy Policy Weighs on Green Investment:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[energy, policy, weighs, on, green, investment...</td>\n",
       "      <td>[52, 733, 4427, 86, 4000, 954, 7875, 68, 66, 887]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288200</th>\n",
       "      <td>288200</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>Osborne May Extend U.K. Austerity to 2018, IFS...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[osborne, may, extend, austerity, to, ifs, says]</td>\n",
       "      <td>[16038, 361, 1760, 51887, 35, 29628, 537]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288201</th>\n",
       "      <td>288201</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:03-05:00</td>\n",
       "      <td>Overnight Rates Surge in Fed’s Operation Twist.</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[overnight, rates, surge, in, fed, operation, ...</td>\n",
       "      <td>[3580, 688, 5259, 88, 683, 1614, 13954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288202</th>\n",
       "      <td>288202</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:53:16-05:00</td>\n",
       "      <td>Japan Copper-Alloy Product Output Climbs 0.5% ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[japan, copper, alloy, product, output, climbs...</td>\n",
       "      <td>[2007, 4173, 15594, 1658, 1197, 7719, 88, 863]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288203</th>\n",
       "      <td>288203</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 20:08:21-05:00</td>\n",
       "      <td>China Yangtze, Jiangsu Shagang, Nanjing Urban:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[china, yangtze, jiangsu, shagang, nanjing, ur...</td>\n",
       "      <td>[945, 34736, 31223, 43023, 14242, 1381, 945, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288204</th>\n",
       "      <td>288204</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 20:33:00-05:00</td>\n",
       "      <td>Analysis: \"Caveat emptor\" as foreigners rush t...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[analysis, caveat, emptor, as, foreigners, rus...</td>\n",
       "      <td>[1140, 17237, 29776, 106, 10425, 371, 35, 1192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288205</th>\n",
       "      <td>288205</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 20:49:56-05:00</td>\n",
       "      <td>Notre Dame Remains No. 1 Team in College Footb...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[notre, dame, remains, no, team, in, college, ...</td>\n",
       "      <td>[73166, 55673, 2640, 206, 2275, 88, 4014, 7031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288206</th>\n",
       "      <td>288206</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 21:00:09-05:00</td>\n",
       "      <td>Stones Roll Back Years, Rock Cheap Seats, No W...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[stones, roll, back, years, rock, cheap, seats...</td>\n",
       "      <td>[34661, 6697, 451, 134, 5019, 987, 2998, 206, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288207</th>\n",
       "      <td>288207</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 21:01:00-05:00</td>\n",
       "      <td>Sebastian Vettel Wins Third Straight Formula O...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[sebastian, vettel, wins, third, straight, for...</td>\n",
       "      <td>[10102, 89655, 7606, 496, 697, 4247, 284, 4630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288208</th>\n",
       "      <td>288208</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 22:30:46-05:00</td>\n",
       "      <td>Thermal Coal Swaps for Indonesia Rise; China C...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[thermal, coal, swaps, for, indonesia, rise, c...</td>\n",
       "      <td>[7979, 7978, 3331, 80, 2173, 580, 945, 3844, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288209</th>\n",
       "      <td>288209</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 22:45:00-05:00</td>\n",
       "      <td>Qatar cashes in on remaining Barclays warrants.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[qatar, cashes, in, on, remaining, barclays, w...</td>\n",
       "      <td>[12542, 15045, 88, 86, 3574, 5082, 13707]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288210</th>\n",
       "      <td>288210</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 22:50:55-05:00</td>\n",
       "      <td>China Cosco and ICICI Bank Market Debt; Asia B...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[china, cosco, and, icici, bank, market, debt,...</td>\n",
       "      <td>[945, 66962, 62, 23037, 696, 300, 1548, 1209, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288211</th>\n",
       "      <td>288211</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:31:17-05:00</td>\n",
       "      <td>Giants Beat Packers 38-10 to End Two-Game NFL ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[giants, beat, packers, to, end, two, game, nf...</td>\n",
       "      <td>[8446, 1765, 30527, 35, 36, 216, 680, 18761, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288212</th>\n",
       "      <td>288212</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:45:15-05:00</td>\n",
       "      <td>Hong Kong Short Selling Turnover Recorded 11/2...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[hong, kong, short, selling, turnover, recorded]</td>\n",
       "      <td>[3801, 3802, 328, 1559, 9363, 2960]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288213</th>\n",
       "      <td>288213</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:47:46-05:00</td>\n",
       "      <td>China Avic Avionics Rises as Jet Lands Success...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[china, avic, avionics, rises, as, jet, lands,...</td>\n",
       "      <td>[945, 28131, 40379, 2607, 106, 2979, 13073, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288214</th>\n",
       "      <td>288214</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:49:23-05:00</td>\n",
       "      <td>Glencore, Vedanta Face Up to 50% Pay-Raise Dem...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[glencore, vedanta, face, up, to, pay, raise, ...</td>\n",
       "      <td>[28310, 15734, 2636, 324, 35, 59, 1680, 1092, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288215 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                      Date                  datetime  \\\n",
       "0            0 2006-10-20 00:00:00-04:00 2006-10-20 16:16:16-04:00   \n",
       "1            1 2006-10-20 00:00:00-04:00 2006-10-20 16:25:00-04:00   \n",
       "2            2 2006-10-20 00:00:00-04:00 2006-10-20 18:15:00-04:00   \n",
       "3            3 2006-10-20 00:00:00-04:00 2006-10-20 20:08:44-04:00   \n",
       "4            4 2006-10-20 00:00:00-04:00 2006-10-21 14:21:00-04:00   \n",
       "5            5 2006-10-20 00:00:00-04:00 2006-10-21 20:11:00-04:00   \n",
       "6            6 2006-10-20 00:00:00-04:00 2006-10-22 06:46:00-04:00   \n",
       "7            7 2006-10-20 00:00:00-04:00 2006-10-22 12:14:00-04:00   \n",
       "8            8 2006-10-20 00:00:00-04:00 2006-10-22 20:36:00-04:00   \n",
       "9            9 2006-10-20 00:00:00-04:00 2006-10-22 21:51:00-04:00   \n",
       "10          10 2006-10-23 00:00:00-04:00 2006-10-23 01:50:00-04:00   \n",
       "11          11 2006-10-23 00:00:00-04:00 2006-10-23 03:47:00-04:00   \n",
       "12          12 2006-10-23 00:00:00-04:00 2006-10-23 03:51:00-04:00   \n",
       "13          13 2006-10-23 00:00:00-04:00 2006-10-23 05:24:00-04:00   \n",
       "14          14 2006-10-23 00:00:00-04:00 2006-10-23 07:51:36-04:00   \n",
       "15          15 2006-10-23 00:00:00-04:00 2006-10-23 08:36:00-04:00   \n",
       "16          16 2006-10-23 00:00:00-04:00 2006-10-23 09:58:00-04:00   \n",
       "17          17 2006-10-23 00:00:00-04:00 2006-10-23 10:47:00-04:00   \n",
       "18          18 2006-10-23 00:00:00-04:00 2006-10-23 10:49:00-04:00   \n",
       "19          19 2006-10-23 00:00:00-04:00 2006-10-23 10:56:00-04:00   \n",
       "20          20 2006-10-23 00:00:00-04:00 2006-10-23 11:18:00-04:00   \n",
       "21          21 2006-10-23 00:00:00-04:00 2006-10-23 11:20:00-04:00   \n",
       "22          22 2006-10-23 00:00:00-04:00 2006-10-23 11:41:00-04:00   \n",
       "23          23 2006-10-23 00:00:00-04:00 2006-10-23 11:48:00-04:00   \n",
       "24          24 2006-10-23 00:00:00-04:00 2006-10-23 11:52:00-04:00   \n",
       "25          25 2006-10-23 00:00:00-04:00 2006-10-23 12:34:00-04:00   \n",
       "26          26 2006-10-23 00:00:00-04:00 2006-10-23 14:10:00-04:00   \n",
       "27          27 2006-10-23 00:00:00-04:00 2006-10-23 15:06:00-04:00   \n",
       "28          28 2006-10-23 00:00:00-04:00 2006-10-23 15:40:00-04:00   \n",
       "29          29 2006-10-23 00:00:00-04:00 2006-10-23 15:48:00-04:00   \n",
       "...        ...                       ...                       ...   \n",
       "288185  288185 2012-11-23 00:00:00-05:00 2012-11-25 18:25:00-05:00   \n",
       "288186  288186 2012-11-23 00:00:00-05:00 2012-11-25 18:30:16-05:00   \n",
       "288187  288187 2012-11-23 00:00:00-05:00 2012-11-25 18:30:17-05:00   \n",
       "288188  288188 2012-11-23 00:00:00-05:00 2012-11-25 18:30:36-05:00   \n",
       "288189  288189 2012-11-23 00:00:00-05:00 2012-11-25 18:30:58-05:00   \n",
       "288190  288190 2012-11-23 00:00:00-05:00 2012-11-25 18:44:00-05:00   \n",
       "288191  288191 2012-11-23 00:00:00-05:00 2012-11-25 18:45:00-05:00   \n",
       "288192  288192 2012-11-23 00:00:00-05:00 2012-11-25 18:52:54-05:00   \n",
       "288193  288193 2012-11-23 00:00:00-05:00 2012-11-25 19:00:01-05:00   \n",
       "288194  288194 2012-11-23 00:00:00-05:00 2012-11-25 19:00:01-05:00   \n",
       "288195  288195 2012-11-23 00:00:00-05:00 2012-11-25 19:00:01-05:00   \n",
       "288196  288196 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288197  288197 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288198  288198 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288199  288199 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288200  288200 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288201  288201 2012-11-23 00:00:00-05:00 2012-11-25 19:01:03-05:00   \n",
       "288202  288202 2012-11-23 00:00:00-05:00 2012-11-25 19:53:16-05:00   \n",
       "288203  288203 2012-11-23 00:00:00-05:00 2012-11-25 20:08:21-05:00   \n",
       "288204  288204 2012-11-23 00:00:00-05:00 2012-11-25 20:33:00-05:00   \n",
       "288205  288205 2012-11-23 00:00:00-05:00 2012-11-25 20:49:56-05:00   \n",
       "288206  288206 2012-11-23 00:00:00-05:00 2012-11-25 21:00:09-05:00   \n",
       "288207  288207 2012-11-23 00:00:00-05:00 2012-11-25 21:01:00-05:00   \n",
       "288208  288208 2012-11-23 00:00:00-05:00 2012-11-25 22:30:46-05:00   \n",
       "288209  288209 2012-11-23 00:00:00-05:00 2012-11-25 22:45:00-05:00   \n",
       "288210  288210 2012-11-23 00:00:00-05:00 2012-11-25 22:50:55-05:00   \n",
       "288211  288211 2012-11-23 00:00:00-05:00 2012-11-25 23:31:17-05:00   \n",
       "288212  288212 2012-11-23 00:00:00-05:00 2012-11-25 23:45:15-05:00   \n",
       "288213  288213 2012-11-23 00:00:00-05:00 2012-11-25 23:47:46-05:00   \n",
       "288214  288214 2012-11-23 00:00:00-05:00 2012-11-25 23:49:23-05:00   \n",
       "\n",
       "                                               news_title     source  stock  \\\n",
       "0       Inco's Net Soars on Higher Metal Prices, Break...  Bloomberg      1   \n",
       "1       Hey buddy, can you spare $600 for a Google sha...    Reuters      1   \n",
       "2          Exxon Mobil offers plan to end Alaska dispute.    Reuters      1   \n",
       "3       Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...  Bloomberg      1   \n",
       "4       AOL CEO says sales may shrink for two years -p...    Reuters      1   \n",
       "5       Pluspetrol says losing $2.4 mln/day in Peru pr...    Reuters      1   \n",
       "6               EU to urge China to open economy further.    Reuters      1   \n",
       "7            Fed to keep hawkish tone, hold rates steady.    Reuters      1   \n",
       "8                    Weatherford profit jumps 78 percent.    Reuters      1   \n",
       "9       Saudi Arabia tells Japan to cut its Nov crude ...    Reuters      1   \n",
       "10        Australia's Foster's says confident on targets.    Reuters      1   \n",
       "11      Macquarie bids $1.4 bln for metering firm Techem.    Reuters      1   \n",
       "12      DaimlerChrysler talks to 2 firms on small car:...    Reuters      1   \n",
       "13              More solid earnings may keep rally going.    Reuters      1   \n",
       "14      EU Energy Chief Backs German Plan for Price Co...  Bloomberg      1   \n",
       "15      U.S. venture investors betting on energy, Web ...    Reuters      1   \n",
       "16        Shell Canada jumps 30 pct on Royal Dutch offer.    Reuters      1   \n",
       "17            Kimberly-Clark sees higher costs this year.    Reuters      1   \n",
       "18                           Ford won't sell Ford Credit.    Reuters      1   \n",
       "19            Ford sees fourth quarter weaker than third.    Reuters      1   \n",
       "20                      Hasbro profit beats expectations.    Reuters      1   \n",
       "21                   Merrill Lynch to buy Petrie Parkman.    Reuters      1   \n",
       "22         Ford CEO: Jury out on European premium brands.    Reuters      1   \n",
       "23            Kimberly-Clark profit higher, narrows view.    Reuters      1   \n",
       "24      Wal-Mart October sales growth tracking below f...    Reuters      1   \n",
       "25      Bombardier could launch new jet this year: ana...    Reuters      1   \n",
       "26      Private equity groups form for Tribune bid: so...    Reuters      1   \n",
       "27                       AT&T earnings beat expectations.    Reuters      1   \n",
       "28       Wrigley sees no change in communications policy.    Reuters      1   \n",
       "29           Ford is reviewing all products, brands: CEO.    Reuters      1   \n",
       "...                                                   ...        ...    ...   \n",
       "288185      Mexico \"Buen Fin\" sales up by nearly a third.    Reuters      0   \n",
       "288186   Fed’s Dudley Signals a Shift Toward Bank Reform.  Bloomberg      0   \n",
       "288187  Natural-Gas Exports Could Lift U.S. Trade and ...  Bloomberg      0   \n",
       "288188  Spain’s Bad Bank Needs Goodwill From Europe’s ...  Bloomberg      0   \n",
       "288189   Regulate U.S. Markets Like the Nuclear Industry.  Bloomberg      0   \n",
       "288190  Black Friday sales online top $1 billion for f...    Reuters      0   \n",
       "288191  Apple seeks to add more products to Samsung pa...    Reuters      0   \n",
       "288192  Qantas Minds Bonds as Dreamliner Order Pulled:...  Bloomberg      0   \n",
       "288193  BBC’s Chief Honed Skills Saving Covent Garden:...  Bloomberg      0   \n",
       "288194  White Burgundies From Cote d’Or Set Gold Stand...  Bloomberg      0   \n",
       "288195  Chelsea Ties 0-0 Against Man. City as Fans Jee...  Bloomberg      0   \n",
       "288196  Britons’ Spending Power Stagnated in October o...  Bloomberg      0   \n",
       "288197  U.K. Business Investment Seen at Pace Damping ...  Bloomberg      0   \n",
       "288198  Colombia Bank Votes 4-3 for Rate Cut After Bro...  Bloomberg      0   \n",
       "288199  U.K. Energy Policy Weighs on Green Investment:...  Bloomberg      0   \n",
       "288200  Osborne May Extend U.K. Austerity to 2018, IFS...  Bloomberg      0   \n",
       "288201    Overnight Rates Surge in Fed’s Operation Twist.  Bloomberg      0   \n",
       "288202  Japan Copper-Alloy Product Output Climbs 0.5% ...  Bloomberg      0   \n",
       "288203  China Yangtze, Jiangsu Shagang, Nanjing Urban:...  Bloomberg      0   \n",
       "288204  Analysis: \"Caveat emptor\" as foreigners rush t...    Reuters      0   \n",
       "288205  Notre Dame Remains No. 1 Team in College Footb...  Bloomberg      0   \n",
       "288206  Stones Roll Back Years, Rock Cheap Seats, No W...  Bloomberg      0   \n",
       "288207  Sebastian Vettel Wins Third Straight Formula O...  Bloomberg      0   \n",
       "288208  Thermal Coal Swaps for Indonesia Rise; China C...  Bloomberg      0   \n",
       "288209    Qatar cashes in on remaining Barclays warrants.    Reuters      0   \n",
       "288210  China Cosco and ICICI Bank Market Debt; Asia B...  Bloomberg      0   \n",
       "288211  Giants Beat Packers 38-10 to End Two-Game NFL ...  Bloomberg      0   \n",
       "288212  Hong Kong Short Selling Turnover Recorded 11/2...  Bloomberg      0   \n",
       "288213  China Avic Avionics Rises as Jet Lands Success...  Bloomberg      0   \n",
       "288214  Glencore, Vedanta Face Up to 50% Pay-Raise Dem...  Bloomberg      0   \n",
       "\n",
       "                                                    words  \\\n",
       "0       [inco, net, soars, on, higher, metal, prices, ...   \n",
       "1       [hey, buddy, can, you, spare, for, google, share]   \n",
       "2       [exxon, mobil, offers, plan, to, end, alaska, ...   \n",
       "3       [jim, cramer, diageo, anheuser, busch, monster...   \n",
       "4       [aol, ceo, says, sales, may, shrink, for, two,...   \n",
       "5       [pluspetrol, says, losing, mln, day, in, peru,...   \n",
       "6       [eu, to, urge, china, to, open, economy, further]   \n",
       "7       [fed, to, keep, hawkish, tone, hold, rates, st...   \n",
       "8                   [weatherford, profit, jumps, percent]   \n",
       "9       [saudi, arabia, tells, japan, to, cut, its, no...   \n",
       "10      [australia, foster, says, confident, on, targets]   \n",
       "11      [macquarie, bids, bln, for, metering, firm, te...   \n",
       "12      [daimlerchrysler, talks, to, firms, on, small,...   \n",
       "13       [more, solid, earnings, may, keep, rally, going]   \n",
       "14      [eu, energy, chief, backs, german, plan, for, ...   \n",
       "15         [venture, investors, betting, on, energy, web]   \n",
       "16      [shell, canada, jumps, pct, on, royal, dutch, ...   \n",
       "17      [kimberly, clark, sees, higher, costs, this, y...   \n",
       "18                        [ford, won, sell, ford, credit]   \n",
       "19      [ford, sees, fourth, quarter, weaker, than, th...   \n",
       "20                  [hasbro, profit, beats, expectations]   \n",
       "21             [merrill, lynch, to, buy, petrie, parkman]   \n",
       "22      [ford, ceo, jury, out, on, european, premium, ...   \n",
       "23       [kimberly, clark, profit, higher, narrows, view]   \n",
       "24      [wal, mart, october, sales, growth, tracking, ...   \n",
       "25      [bombardier, could, launch, new, jet, this, ye...   \n",
       "26      [private, equity, groups, form, for, tribune, ...   \n",
       "27                     [at, earnings, beat, expectations]   \n",
       "28      [wrigley, sees, no, change, in, communications...   \n",
       "29      [ford, is, reviewing, all, products, brands, ceo]   \n",
       "...                                                   ...   \n",
       "288185  [mexico, buen, fin, sales, up, by, nearly, third]   \n",
       "288186  [fed, dudley, signals, shift, toward, bank, re...   \n",
       "288187  [natural, gas, exports, could, lift, trade, an...   \n",
       "288188  [spain, bad, bank, needs, goodwill, from, euro...   \n",
       "288189  [regulate, markets, like, the, nuclear, industry]   \n",
       "288190  [black, friday, sales, online, top, billion, f...   \n",
       "288191  [apple, seeks, to, add, more, products, to, sa...   \n",
       "288192  [qantas, minds, bonds, as, dreamliner, order, ...   \n",
       "288193  [bbc, chief, honed, skills, saving, covent, ga...   \n",
       "288194  [white, burgundies, from, cote, or, set, gold,...   \n",
       "288195  [chelsea, ties, against, man, city, as, fans, ...   \n",
       "288196  [britons, spending, power, stagnated, in, octo...   \n",
       "288197  [business, investment, seen, at, pace, damping...   \n",
       "288198  [colombia, bank, votes, for, rate, cut, after,...   \n",
       "288199  [energy, policy, weighs, on, green, investment...   \n",
       "288200   [osborne, may, extend, austerity, to, ifs, says]   \n",
       "288201  [overnight, rates, surge, in, fed, operation, ...   \n",
       "288202  [japan, copper, alloy, product, output, climbs...   \n",
       "288203  [china, yangtze, jiangsu, shagang, nanjing, ur...   \n",
       "288204  [analysis, caveat, emptor, as, foreigners, rus...   \n",
       "288205  [notre, dame, remains, no, team, in, college, ...   \n",
       "288206  [stones, roll, back, years, rock, cheap, seats...   \n",
       "288207  [sebastian, vettel, wins, third, straight, for...   \n",
       "288208  [thermal, coal, swaps, for, indonesia, rise, c...   \n",
       "288209  [qatar, cashes, in, on, remaining, barclays, w...   \n",
       "288210  [china, cosco, and, icici, bank, market, debt,...   \n",
       "288211  [giants, beat, packers, to, end, two, game, nf...   \n",
       "288212   [hong, kong, short, selling, turnover, recorded]   \n",
       "288213  [china, avic, avionics, rises, as, jet, lands,...   \n",
       "288214  [glencore, vedanta, face, up, to, pay, raise, ...   \n",
       "\n",
       "                                               embeddings  \n",
       "0       [4185, 1198, 8081, 86, 373, 7597, 418, 20386, ...  \n",
       "1                 [266, 267, 182, 268, 269, 80, 270, 271]  \n",
       "2                        [31, 32, 33, 34, 35, 36, 37, 38]  \n",
       "3       [2243, 12399, 31064, 4988, 4989, 7611, 1391, 270]  \n",
       "4       [535, 536, 537, 538, 361, 539, 80, 216, 134, 540]  \n",
       "5                 [885, 537, 175, 886, 887, 88, 888, 889]  \n",
       "6                  [943, 35, 944, 945, 35, 946, 693, 644]  \n",
       "7                 [683, 35, 684, 685, 686, 687, 688, 689]  \n",
       "8                                  [1186, 460, 1187, 310]  \n",
       "9       [1944, 1945, 2006, 2007, 35, 822, 167, 2008, 9...  \n",
       "10                       [1217, 1218, 537, 1219, 86, 289]  \n",
       "11                [3031, 3032, 3033, 80, 3034, 657, 3035]  \n",
       "12               [1113, 663, 35, 1114, 86, 10, 1115, 540]  \n",
       "13                  [162, 1756, 336, 361, 684, 1757, 787]  \n",
       "14          [943, 52, 554, 10553, 563, 34, 80, 288, 1405]  \n",
       "15                           [2074, 501, 2075, 86, 52, 7]  \n",
       "16          [1889, 1206, 1187, 2027, 86, 1896, 1897, 110]  \n",
       "17                 [1795, 1796, 1751, 373, 1142, 92, 222]  \n",
       "18                          [1469, 1660, 678, 1469, 1604]  \n",
       "19                 [1469, 1751, 1656, 497, 801, 163, 496]  \n",
       "20                                 [2449, 460, 2450, 720]  \n",
       "21                       [344, 2203, 35, 649, 2204, 2205]  \n",
       "22            [1469, 536, 1622, 399, 86, 616, 1623, 1569]  \n",
       "23                        [1795, 1796, 460, 373, 2543, 8]  \n",
       "24           [1293, 1294, 863, 538, 314, 2863, 1309, 795]  \n",
       "25             [2978, 326, 1009, 180, 2979, 92, 222, 356]  \n",
       "26            [2754, 523, 929, 2755, 80, 2756, 672, 1176]  \n",
       "27                                  [515, 336, 1765, 720]  \n",
       "28                  [2359, 1751, 206, 745, 88, 2360, 733]  \n",
       "29                [1469, 131, 1568, 177, 1164, 1569, 536]  \n",
       "...                                                   ...  \n",
       "288185        [2475, 84835, 8832, 538, 324, 39, 176, 496]  \n",
       "288186          [683, 39510, 4488, 1093, 2552, 696, 1043]  \n",
       "288187             [95, 74, 988, 326, 2391, 363, 62, 693]  \n",
       "288188       [5372, 2178, 696, 968, 3372, 333, 662, 4149]  \n",
       "288189                   [14044, 426, 316, 66, 3295, 645]  \n",
       "288190  [9445, 87, 538, 604, 1443, 130, 80, 792, 403, ...  \n",
       "288191  [4307, 8803, 35, 1927, 162, 1164, 35, 6115, 27...  \n",
       "288192  [15486, 2649, 4772, 106, 5403, 329, 5100, 1217...  \n",
       "288193  [16611, 554, 25269, 15128, 4584, 85405, 11544,...  \n",
       "288194    [3279, 86934, 333, 24654, 334, 382, 8961, 1810]  \n",
       "288195  [7138, 1032, 1026, 2537, 1370, 106, 12710, 594...  \n",
       "288196  [29544, 1194, 1110, 22094, 88, 863, 86, 754, 6...  \n",
       "288197        [480, 954, 1107, 515, 798, 38960, 962, 314]  \n",
       "288198  [6648, 696, 2440, 80, 828, 822, 202, 5202, 24553]  \n",
       "288199  [52, 733, 4427, 86, 4000, 954, 7875, 68, 66, 887]  \n",
       "288200          [16038, 361, 1760, 51887, 35, 29628, 537]  \n",
       "288201            [3580, 688, 5259, 88, 683, 1614, 13954]  \n",
       "288202     [2007, 4173, 15594, 1658, 1197, 7719, 88, 863]  \n",
       "288203  [945, 34736, 31223, 43023, 14242, 1381, 945, 8...  \n",
       "288204  [1140, 17237, 29776, 106, 10425, 371, 35, 1192...  \n",
       "288205  [73166, 55673, 2640, 206, 2275, 88, 4014, 7031...  \n",
       "288206  [34661, 6697, 451, 134, 5019, 987, 2998, 206, ...  \n",
       "288207  [10102, 89655, 7606, 496, 697, 4247, 284, 4630...  \n",
       "288208  [7979, 7978, 3331, 80, 2173, 580, 945, 3844, 1...  \n",
       "288209          [12542, 15045, 88, 86, 3574, 5082, 13707]  \n",
       "288210  [945, 66962, 62, 23037, 696, 300, 1548, 1209, ...  \n",
       "288211  [8446, 1765, 30527, 35, 36, 216, 680, 18761, 1...  \n",
       "288212                [3801, 3802, 328, 1559, 9363, 2960]  \n",
       "288213  [945, 28131, 40379, 2607, 106, 2979, 13073, 10...  \n",
       "288214  [28310, 15734, 2636, 324, 35, 59, 1680, 1092, ...  \n",
       "\n",
       "[288215 rows x 8 columns]"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['embeddings'] = [np.squeeze(x) for x in np.split(train_embed, train_embed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['embeddings'] = [embedding_matrix[x] for x in train_df['embeddings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:, ['news_title']] = test_df.loc[:, ['news_title']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "test_df['words'] = test_df.news_title.map(simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to sequence\n",
    "test_df['embeddings'] = t.texts_to_sequences(test_df['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "test_embed = pad_sequences(test_df['embeddings'], maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['embeddings'] = [np.squeeze(x) for x in np.split(test_embed, test_embed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['embeddings'] = [embedding_matrix[x] for x in test_df['embeddings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate events by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['stock'] = train_df['stock'].astype(int)\n",
    "test_df['stock'] = test_df['stock'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>news_title</th>\n",
       "      <th>source</th>\n",
       "      <th>stock</th>\n",
       "      <th>words</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:16:16-04:00</td>\n",
       "      <td>Inco's Net Soars on Higher Metal Prices, Break...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[inco, net, soars, on, higher, metal, prices, ...</td>\n",
       "      <td>[[-0.3715226352214813, 0.684317409992218, -1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:25:00-04:00</td>\n",
       "      <td>Hey buddy, can you spare $600 for a Google sha...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, buddy, can, you, spare, for, google, share]</td>\n",
       "      <td>[[0.32294243574142456, -0.03166818246245384, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 18:15:00-04:00</td>\n",
       "      <td>Exxon Mobil offers plan to end Alaska dispute.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[exxon, mobil, offers, plan, to, end, alaska, ...</td>\n",
       "      <td>[[0.09510381519794464, 0.34654828906059265, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 20:08:44-04:00</td>\n",
       "      <td>Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[jim, cramer, diageo, anheuser, busch, monster...</td>\n",
       "      <td>[[0.812869668006897, 0.0374612882733345, 0.543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-21 14:21:00-04:00</td>\n",
       "      <td>AOL CEO says sales may shrink for two years -p...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[aol, ceo, says, sales, may, shrink, for, two,...</td>\n",
       "      <td>[[0.05968537926673889, 0.16134525835514069, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                      Date                  datetime  \\\n",
       "0      0 2006-10-20 00:00:00-04:00 2006-10-20 16:16:16-04:00   \n",
       "1      1 2006-10-20 00:00:00-04:00 2006-10-20 16:25:00-04:00   \n",
       "2      2 2006-10-20 00:00:00-04:00 2006-10-20 18:15:00-04:00   \n",
       "3      3 2006-10-20 00:00:00-04:00 2006-10-20 20:08:44-04:00   \n",
       "4      4 2006-10-20 00:00:00-04:00 2006-10-21 14:21:00-04:00   \n",
       "\n",
       "                                          news_title     source  stock  \\\n",
       "0  Inco's Net Soars on Higher Metal Prices, Break...  Bloomberg      1   \n",
       "1  Hey buddy, can you spare $600 for a Google sha...    Reuters      1   \n",
       "2     Exxon Mobil offers plan to end Alaska dispute.    Reuters      1   \n",
       "3  Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...  Bloomberg      1   \n",
       "4  AOL CEO says sales may shrink for two years -p...    Reuters      1   \n",
       "\n",
       "                                               words  \\\n",
       "0  [inco, net, soars, on, higher, metal, prices, ...   \n",
       "1  [hey, buddy, can, you, spare, for, google, share]   \n",
       "2  [exxon, mobil, offers, plan, to, end, alaska, ...   \n",
       "3  [jim, cramer, diageo, anheuser, busch, monster...   \n",
       "4  [aol, ceo, says, sales, may, shrink, for, two,...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[-0.3715226352214813, 0.684317409992218, -1.1...  \n",
       "1  [[0.32294243574142456, -0.03166818246245384, -...  \n",
       "2  [[0.09510381519794464, 0.34654828906059265, -0...  \n",
       "3  [[0.812869668006897, 0.0374612882733345, 0.543...  \n",
       "4  [[0.05968537926673889, 0.16134525835514069, -0...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = train_df.groupby('Date')\n",
    "\n",
    "agg_train_df = pd.concat([g.embeddings.apply(np.mean, axis=0),\n",
    "                          g.stock.apply(np.mean, axis=0)\n",
    "                         ],\n",
    "                         axis=1)\n",
    "\n",
    "agg_train_df.reset_index(inplace=True)\n",
    "\n",
    "agg_train_df.to_pickle('agg_train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = test_df.groupby('Date')\n",
    "\n",
    "agg_test_df = pd.concat([g.embeddings.apply(np.mean, axis=0),\n",
    "                          g.stock.apply(np.mean, axis=0)\n",
    "                         ],\n",
    "                         axis=1)\n",
    "\n",
    "agg_test_df.reset_index(inplace=True)\n",
    "\n",
    "agg_test_df.to_pickle('agg_test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train_df = pd.read_pickle('agg_train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_test_df = pd.read_pickle('agg_train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back from series of arrays to large array of (events, maxlen, embedding_dims)\n",
    "x_train = np.array(agg_train_df.embeddings.to_list())\n",
    "y_train = np.array(agg_train_df.stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back from series of arrays to large array of (events, maxlen, embedding_dims)\n",
    "x_test = np.array(agg_test_df.embeddings.to_list())\n",
    "y_test = np.array(agg_test_df.stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_penalty = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1534, 20, 100)\n",
      "(?, 1534, 100)\n",
      "(?, 1534, 100)\n"
     ]
    }
   ],
   "source": [
    "# Take real inputs\n",
    "event_in_ = Input(shape=(seqlen, maxlen, embedding_dim), dtype='float32', name='x_train')\n",
    "print(event_in_.shape)\n",
    "# # Average embeddings for o1, p, o2\n",
    "average = keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=2))\n",
    "event_ = average(event_in_) # Output dim (100)\n",
    "print(event_.shape)\n",
    "\n",
    "# Hidden layer\n",
    "hidden1_ = keras.layers.Dense(units=100, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(event_)\n",
    "\n",
    "event_day_ = Conv1D(filters=embedding_dim, kernel_size=1, strides=1, padding='same', activation='relu',\n",
    "                    use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                   )(hidden1_)\n",
    "\n",
    "event_week_ = Conv1D(filters=embedding_dim, kernel_size=5, strides=1, padding='causal', activation='relu',\n",
    "                     use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                    )(hidden1_)\n",
    "\n",
    "event_month_ = Conv1D(filters=embedding_dim, kernel_size=20, strides=1, padding='causal', activation='relu',\n",
    "                      use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                     )(hidden1_)\n",
    "\n",
    "\n",
    "# # Max pooling of weekly and monthly events\n",
    "max_pool_week_ = MaxPooling1D(pool_size=3, strides=1, padding='same', data_format='channels_last'\n",
    "                              )(event_week_)\n",
    "print(max_pool_week_.shape)\n",
    "max_pool_month_ = MaxPooling1D(pool_size=3, strides=1, padding='same', data_format='channels_last'\n",
    "                              )(event_month_)\n",
    "\n",
    "# # Concatenate daily, weekly, monthly\n",
    "concat_ = keras.layers.Concatenate(axis=2)([event_day_, max_pool_week_, max_pool_month_])\n",
    "\n",
    "# Hidden layer\n",
    "hidden2_ = keras.layers.Dense(units=50, activation='relu', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(concat_)\n",
    "\n",
    "# Softmax layer\n",
    "y_pred_ = keras.layers.Dense(units=1, activation='sigmoid', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(hidden2_)\n",
    "\n",
    "model = Model(inputs=event_in_, outputs=y_pred_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.001, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 5.0748 - acc: 0.4583\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0730 - acc: 0.4628\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0712 - acc: 0.4831\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0694 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0677 - acc: 0.5104\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0659 - acc: 0.5248\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0641 - acc: 0.5443\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0623 - acc: 0.5476\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0606 - acc: 0.5489\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0588 - acc: 0.5476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29cb283b748>"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=np.expand_dims(x_train, 0),\n",
    "          y=np.expand_dims(np.expand_dims(y_train, -1), 0), \n",
    "          batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(x=np.expand_dims(x_test, 0), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50105786"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1534, 20, 100)\n",
      "(?, 1534, 100)\n"
     ]
    }
   ],
   "source": [
    "# Embed events\n",
    "# Take training events and return embedded vectors\n",
    "# Create copy of training events, randomly sample events from data, return embedded vectors\n",
    "# Multiply each by tensor\n",
    "# Calculate loss\n",
    "\n",
    "\n",
    "# Take real inputs\n",
    "event_in_ = Input(shape=(seqlen, maxlen, embedding_dim), dtype='float32', name='x_train')\n",
    "print(event_in_.shape)\n",
    "# # Average embeddings for o1, p, o2\n",
    "average = keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=2))\n",
    "event_ = average(event_in_) # Output dim (100)\n",
    "print(event_.shape)\n",
    "\n",
    "# Hidden layer\n",
    "event_day_ = Conv1D(filters=embedding_dim, kernel_size=1, strides=1, padding='same', activation='relu',\n",
    "                    use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                   )(event_)\n",
    "\n",
    "event_week_ = Conv1D(filters=embedding_dim, kernel_size=5, strides=1, padding='causal', activation='relu',\n",
    "                     use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                    )(event_)\n",
    "\n",
    "event_month_ = Conv1D(filters=embedding_dim, kernel_size=20, strides=1, padding='causal', activation='relu',\n",
    "                      use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                     )(event_)\n",
    "\n",
    "\n",
    "# # Max pooling of weekly and monthly events\n",
    "# # Narrow convolution of 3 neighbouring\n",
    "# event_week_ = MaxPooling1D(pool_size=5, strides=None, padding='valid', data_format='channels_last'\n",
    "#                           )(event_week_)\n",
    "\n",
    "# max_pool_month_ = MaxPooling1D(pool_size=3, strides=None, padding='valid', data_format='channels_last'\n",
    "#                               )(event_month_)\n",
    "\n",
    "# # Concatenate daily, weekly, monthly\n",
    "concat_ = keras.layers.Concatenate(axis=2)([event_day_, event_week_, event_month_])\n",
    "\n",
    "# Hidden layer\n",
    "hidden_ = keras.layers.Dense(units=50, activation='relu', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(concat_)\n",
    "\n",
    "y_pred_ = keras.layers.Flatten()(hidden_)\n",
    "model = Model(inputs=event_in_, outputs=y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='hinge',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected flatten_4 to have shape (76700,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-263-9c918fc4f7c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(x=np.expand_dims(x_train, 0),\n\u001b[0;32m      2\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           batch_size=1, epochs=50)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected flatten_4 to have shape (76700,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.fit(x=np.expand_dims(x_train, 0),\n",
    "          y=np.expand_dims(y_train, -1),\n",
    "          batch_size=1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
