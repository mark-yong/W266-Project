{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract News Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'ReutersNews106521'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths=[]\n",
    "for root,d_names,f_names in os.walk(dir):\n",
    "\tfor f in f_names:\n",
    "\t\tfilepaths.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract events to newslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslist = []\n",
    "timelist = []\n",
    "exceptlist = []\n",
    "\n",
    "for file in filepaths:\n",
    "    try:\n",
    "        f = open(file, encoding='utf8')\n",
    "        line1 = f.readline()\n",
    "        line2 = f.readline()\n",
    "        line3 = f.readline()\n",
    "        newslist.append(line1)\n",
    "        timelist.append(line3)\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        exceptlist.append(file)\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslist = [x[3:-1] + '.' for x in newslist]\n",
    "timelist = [x[3:-1] for x in timelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'datetime': time_list, 'news_title': newslist, 'line_num': linelist})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['datetime'] = pd.to_datetime(news_df['datetime'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['source'] = 'Reuters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['tz'] = [x[-3:] for x in time_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timezone conversion to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_bool = news_df['tz']=='EDT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['datetime'] = news_df['datetime'].dt.tz_localize(tz='US/Eastern', ambiguous=tz_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['datetime'] = news_df['datetime'].dt.tz_convert('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.drop('tz', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write news to newslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('./newslist', 'w', encoding='utf8') as f:\n",
    "#     for item in newslist:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./timelist', 'w', encoding='utf8') as f:\n",
    "#     for item in time_list:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslist = [line.rstrip('\\n') for line in open('./newslist', encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = [line.rstrip('\\n') for line in open('./timelist', encoding='utf8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_list = [datetime.strptime(x[:-4], '%a %b %d, %Y %H:%M%p') for x in time_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloomberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '20061020_20131126_bloomberg_news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths=[]\n",
    "for root,d_names,f_names in os.walk(dir):\n",
    "\tfor f in f_names:\n",
    "\t\tfilepaths.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newslist2 = []\n",
    "# exceptlist2 = []\n",
    "# time_list2 = []\n",
    "\n",
    "# # Turn extracted events into dataframe\n",
    "# o1_list = []\n",
    "# p_list = []\n",
    "# o2_list = []\n",
    "\n",
    "# for event in event_list:\n",
    "#     o1_list.append(event[2])\n",
    "#     p_list.append(event[3])\n",
    "#     o2_list.append(event[4])\n",
    "    \n",
    "# event_ext_df = pd.DataFrame({'line_num': line_num_list, 'o1': o1_list, 'p': p_list, 'o2': o2_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslist2 = [x[3:-1] for x in newslist2]\n",
    "newslist2 = [x + '.' for x in newslist2]\n",
    "time_list2 = [x[3:-1] for x in time_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./newslist_b', 'w', encoding='utf8') as f:\n",
    "#     for item in newslist2:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./time_list_b', 'w', encoding='utf8') as f:\n",
    "#     for item in time_list2:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newslist2 = [line.rstrip('\\n') for line in open('./newslist_b', encoding='utf8')]\n",
    "# time_list2 = [line.rstrip('\\n') for line in open('./time_list_b', encoding='utf8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news2_df = pd.DataFrame({'datetime': time_list2, 'news_title': newslist2})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleanup\n",
    "news2_df = news2_df[news2_df['datetime'] != '']\n",
    "news2_df.reset_index(inplace=True, drop=True)\n",
    "news2_df = news2_df[news2_df['datetime'].str.len() == 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news2_df.loc[:, 'datetime'] = pd.to_datetime(news2_df.loc[:, 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news2_df['source'] = 'Bloomberg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine news sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([news_df, news2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['datetime'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslist = list(df['news_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'datetime'] = df['datetime'].dt.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./news.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./news.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join stock movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dji = pd.read_pickle(\"./dji.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge_asof(left=df, right=dji[['Date', 'stock']], left_on='datetime', right_on='Date', direction='backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=dji[['Date']], right=df, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)\n",
    "df.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['datetime'] <= '2012-11-26']\n",
    "test_df = df[df['datetime'] > '2012-11-26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('./train_df.pkl')\n",
    "test_df.to_pickle('./test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('./train_df.pkl')\n",
    "test_df = pd.read_pickle('./test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./train_news', 'w', encoding='utf8') as f:\n",
    "#     for item in train_df['news_title']:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./test_news', 'w', encoding='utf8') as f:\n",
    "#     for item in test_df['news_title']:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -Xmx512m -jar ./reverb-latest.jar -N train_news > ./train_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## All events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in command line\n",
    "\n",
    "# cd /C/Users/Yonge/Stock_Price_Prediction\n",
    "\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2006*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters06.txt\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2007*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters07.txt\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2008*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters08.txt\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2009*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters09.txt\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2010*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters10.txt\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2011*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters11.txt\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2012*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters12.txt\n",
    "# find ReutersNews106521/ -type f -path \"ReutersNews106521/2013*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters13.txt\n",
    "\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2006*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters06.txt\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2007*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters07.txt\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2008*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters08.txt\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2009*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters09.txt\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2010*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters10.txt\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2011*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters11.txt\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2012*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters12.txt\n",
    "# find 20061020_20131126_bloomberg_news/ -type f -path \"20061020_20131126_bloomberg_news/2013*\" -type f | java -Xmx512m -jar ./reverb-latest.jar -f > ./reuters13.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = []\n",
    "# for i in range(6, 13):\n",
    "#     files.append('reuters' + str(i).zfill(2) + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract all Reuters events\n",
    "# o1_list = []\n",
    "# p_list = []\n",
    "# o2_list = []\n",
    "\n",
    "# for file in files:\n",
    "#     for line in open(file, encoding='utf-8'):\n",
    "#         line = line.rstrip('\\n').split('\\t')\n",
    "#         o1_list.append(line[2])\n",
    "#         p_list.append(line[3])\n",
    "#         o2_list.append(line[4])\n",
    "    \n",
    "# reuters_event_df = pd.DataFrame({'o1': o1_list, 'p': p_list, 'o2': o2_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters_event_df.to_pickle(\"./reuters_event_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = []\n",
    "# for i in range(6, 13):\n",
    "#     files.append('bloomberg' + str(i).zfill(2) + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract all Bloomberg events\n",
    "# o1_list = []\n",
    "# p_list = []\n",
    "# o2_list = []\n",
    "\n",
    "# for file in files:\n",
    "#     print(file)            \n",
    "#     for line in open(file, encoding='utf-8', errors='replace'):\n",
    "#         line = line.rstrip('\\n').split('\\t')\n",
    "#         o1_list.append(line[2])\n",
    "#         p_list.append(line[3])\n",
    "#         o2_list.append(line[4])\n",
    "\n",
    "\n",
    "    \n",
    "# bloomberg_event_df = pd.DataFrame({'o1': o1_list, 'p': p_list, 'o2': o2_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloomberg_event_df.to_pickle(\"./bloomberg_event_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters_event_df = pd.read_pickle(\"./reuters_event_df.pkl\")\n",
    "# bloomberg_event_df = pd.read_pickle(\"./bloomberg_event_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_event_df = pd.concat([reuters_event_df, bloomberg_event_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_event_df.to_pickle(\"./combined_event_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_events_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
