{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Softmax\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "maxlen=20\n",
    "embedding_dim = 100\n",
    "text_vocabulary_size = 140000\n",
    "n_epochs = 500\n",
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_pickle('train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate word_indices with embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, ['news_title']] = train_df.loc[:, ['news_title']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "train_df['words'] = train_df.news_title.map(simple_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open(\"D:\\\\GitHub\\\\glove.6B\\\\glove.6B.100d.txt\", encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and fit on text\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_df['news_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "embedding_matrix = np.zeros((text_vocabulary_size, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a weight matrix for words in training docs\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to sequence\n",
    "train_df['embeddings'] = t.texts_to_sequences(train_df['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "train_embed = pad_sequences(train_df['embeddings'], maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>news_title</th>\n",
       "      <th>source</th>\n",
       "      <th>stock</th>\n",
       "      <th>words</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:16:16-04:00</td>\n",
       "      <td>Inco's Net Soars on Higher Metal Prices, Break...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[inco, net, soars, on, higher, metal, prices, ...</td>\n",
       "      <td>[14411, 222, 1237, 3, 172, 1541, 53, 3018, 1404]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:25:00-04:00</td>\n",
       "      <td>Hey buddy, can you spare $600 for a Google sha...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, buddy, can, you, spare, for, google, share]</td>\n",
       "      <td>[12905, 17975, 440, 2332, 6801, 5, 318, 246]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 18:15:00-04:00</td>\n",
       "      <td>Exxon Mobil offers plan to end Alaska dispute.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[exxon, mobil, offers, plan, to, end, alaska, ...</td>\n",
       "      <td>[1044, 4648, 449, 56, 1, 184, 3089, 788]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 20:08:44-04:00</td>\n",
       "      <td>Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[jim, cramer, diageo, anheuser, busch, monster...</td>\n",
       "      <td>[4543, 24198, 5067, 3019, 3686, 3519, 3090, 318]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-21 14:21:00-04:00</td>\n",
       "      <td>AOL CEO says sales may shrink for two years -p...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[aol, ceo, says, sales, may, shrink, for, two,...</td>\n",
       "      <td>[2528, 49, 4, 10, 11, 2031, 5, 93, 191, 666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-21 20:11:00-04:00</td>\n",
       "      <td>Pluspetrol says losing $2.4 mln/day in Peru pr...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[pluspetrol, says, losing, mln, day, in, peru,...</td>\n",
       "      <td>[24199, 4, 1091, 1165, 68, 2, 847, 1336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 06:46:00-04:00</td>\n",
       "      <td>EU to urge China to open economy further.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[eu, to, urge, china, to, open, economy, further]</td>\n",
       "      <td>[80, 1, 1657, 21, 1, 257, 73, 873]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 12:14:00-04:00</td>\n",
       "      <td>Fed to keep hawkish tone, hold rates steady.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[fed, to, keep, hawkish, tone, hold, rates, st...</td>\n",
       "      <td>[63, 1, 487, 15302, 5407, 492, 171, 851]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 20:36:00-04:00</td>\n",
       "      <td>Weatherford profit jumps 78 percent.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[weatherford, profit, jumps, percent]</td>\n",
       "      <td>[12258, 27, 310, 121]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-22 21:51:00-04:00</td>\n",
       "      <td>Saudi Arabia tells Japan to cut its Nov crude ...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[saudi, arabia, tells, japan, to, cut, its, no...</td>\n",
       "      <td>[398, 1571, 406, 100, 1, 59, 256, 2052, 207, 276]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 01:50:00-04:00</td>\n",
       "      <td>Australia's Foster's says confident on targets.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[australia, foster, says, confident, on, targets]</td>\n",
       "      <td>[292, 7573, 4, 1696, 3, 513]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 03:47:00-04:00</td>\n",
       "      <td>Macquarie bids $1.4 bln for metering firm Techem.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[macquarie, bids, bln, for, metering, firm, te...</td>\n",
       "      <td>[2695, 683, 609, 5, 14408, 568, 41688]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 03:51:00-04:00</td>\n",
       "      <td>DaimlerChrysler talks to 2 firms on small car:...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[daimlerchrysler, talks, to, firms, on, small,...</td>\n",
       "      <td>[6079, 86, 1, 519, 3, 806, 539, 666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 05:24:00-04:00</td>\n",
       "      <td>More solid earnings may keep rally going.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[more, solid, earnings, may, keep, rally, going]</td>\n",
       "      <td>[43, 3068, 148, 11, 487, 185, 3149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 07:51:36-04:00</td>\n",
       "      <td>EU Energy Chief Backs German Plan for Price Co...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[eu, energy, chief, backs, german, plan, for, ...</td>\n",
       "      <td>[80, 143, 153, 713, 122, 56, 5, 125, 1968]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 08:36:00-04:00</td>\n",
       "      <td>U.S. venture investors betting on energy, Web ...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[venture, investors, betting, on, energy, web]</td>\n",
       "      <td>[659, 145, 3926, 3, 143, 1200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 09:58:00-04:00</td>\n",
       "      <td>Shell Canada jumps 30 pct on Royal Dutch offer.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[shell, canada, jumps, pct, on, royal, dutch, ...</td>\n",
       "      <td>[848, 234, 310, 754, 3, 2032, 1321, 205]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 10:47:00-04:00</td>\n",
       "      <td>Kimberly-Clark sees higher costs this year.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[kimberly, clark, sees, higher, costs, this, y...</td>\n",
       "      <td>[6311, 4037, 54, 172, 183, 215, 28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 10:49:00-04:00</td>\n",
       "      <td>Ford won't sell Ford Credit.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, won, sell, ford, credit]</td>\n",
       "      <td>[416, 1036, 107, 416, 62]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 10:56:00-04:00</td>\n",
       "      <td>Ford sees fourth quarter weaker than third.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, sees, fourth, quarter, weaker, than, th...</td>\n",
       "      <td>[416, 54, 403, 87, 1192, 112, 170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:18:00-04:00</td>\n",
       "      <td>Hasbro profit beats expectations.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[hasbro, profit, beats, expectations]</td>\n",
       "      <td>[5408, 27, 213, 912]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:20:00-04:00</td>\n",
       "      <td>Merrill Lynch to buy Petrie Parkman.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[merrill, lynch, to, buy, petrie, parkman]</td>\n",
       "      <td>[801, 2861, 1, 70, 32331, 41689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:41:00-04:00</td>\n",
       "      <td>Ford CEO: Jury out on European premium brands.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, ceo, jury, out, on, european, premium, ...</td>\n",
       "      <td>[416, 49, 1645, 214, 3, 111, 1201, 1612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:48:00-04:00</td>\n",
       "      <td>Kimberly-Clark profit higher, narrows view.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[kimberly, clark, profit, higher, narrows, view]</td>\n",
       "      <td>[6311, 4037, 27, 172, 987, 106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 11:52:00-04:00</td>\n",
       "      <td>Wal-Mart October sales growth tracking below f...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[wal, mart, october, sales, growth, tracking, ...</td>\n",
       "      <td>[534, 551, 467, 10, 34, 3989, 704, 110]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 12:34:00-04:00</td>\n",
       "      <td>Bombardier could launch new jet this year: ana...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[bombardier, could, launch, new, jet, this, ye...</td>\n",
       "      <td>[3540, 274, 1364, 26, 1316, 215, 28, 744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 14:10:00-04:00</td>\n",
       "      <td>Private equity groups form for Tribune bid: so...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[private, equity, groups, form, for, tribune, ...</td>\n",
       "      <td>[465, 139, 1741, 1924, 5, 1405, 92, 314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 15:06:00-04:00</td>\n",
       "      <td>AT&amp;T earnings beat expectations.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[at, earnings, beat, expectations]</td>\n",
       "      <td>[17, 148, 421, 912]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 15:40:00-04:00</td>\n",
       "      <td>Wrigley sees no change in communications policy.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[wrigley, sees, no, change, in, communications...</td>\n",
       "      <td>[10035, 54, 120, 635, 2, 2910, 295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>2006-10-23 15:48:00-04:00</td>\n",
       "      <td>Ford is reviewing all products, brands: CEO.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[ford, is, reviewing, all, products, brands, ceo]</td>\n",
       "      <td>[416, 66, 3601, 584, 909, 1612, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288185</th>\n",
       "      <td>288185</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:25:00-05:00</td>\n",
       "      <td>Mexico \"Buen Fin\" sales up by nearly a third.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[mexico, buen, fin, sales, up, by, nearly, third]</td>\n",
       "      <td>[392, 41686, 5615, 10, 39, 22, 2163, 170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288186</th>\n",
       "      <td>288186</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:16-05:00</td>\n",
       "      <td>Fed’s Dudley Signals a Shift Toward Bank Reform.</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[fed, dudley, signals, shift, toward, bank, re...</td>\n",
       "      <td>[63, 2722, 791, 1271, 1389, 18, 642]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288187</th>\n",
       "      <td>288187</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:17-05:00</td>\n",
       "      <td>Natural-Gas Exports Could Lift U.S. Trade and ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[natural, gas, exports, could, lift, trade, an...</td>\n",
       "      <td>[511, 127, 248, 274, 1098, 179, 47, 73]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288188</th>\n",
       "      <td>288188</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:36-05:00</td>\n",
       "      <td>Spain’s Bad Bank Needs Goodwill From Europe’s ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[spain, bad, bank, needs, goodwill, from, euro...</td>\n",
       "      <td>[199, 901, 18, 466, 9488, 29, 84, 667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288189</th>\n",
       "      <td>288189</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:30:58-05:00</td>\n",
       "      <td>Regulate U.S. Markets Like the Nuclear Industry.</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[regulate, markets, like, the, nuclear, industry]</td>\n",
       "      <td>[7094, 144, 1530, 55, 488, 491]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288190</th>\n",
       "      <td>288190</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:44:00-05:00</td>\n",
       "      <td>Black Friday sales online top $1 billion for f...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[black, friday, sales, online, top, billion, f...</td>\n",
       "      <td>[1104, 1947, 10, 907, 174, 16, 5, 48, 190, 8253]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288191</th>\n",
       "      <td>288191</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:45:00-05:00</td>\n",
       "      <td>Apple seeks to add more products to Samsung pa...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[apple, seeks, to, add, more, products, to, sa...</td>\n",
       "      <td>[236, 103, 1, 749, 43, 909, 1, 670, 887, 612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288192</th>\n",
       "      <td>288192</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 18:52:54-05:00</td>\n",
       "      <td>Qantas Minds Bonds as Dreamliner Order Pulled:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[qantas, minds, bonds, as, dreamliner, order, ...</td>\n",
       "      <td>[1832, 8037, 57, 6, 3692, 651, 5218, 292, 62]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288193</th>\n",
       "      <td>288193</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:00:01-05:00</td>\n",
       "      <td>BBC’s Chief Honed Skills Saving Covent Garden:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[bbc, chief, honed, skills, saving, covent, ga...</td>\n",
       "      <td>[3311, 153, 35376, 6688, 3894, 21973, 6546, 9535]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288194</th>\n",
       "      <td>288194</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:00:01-05:00</td>\n",
       "      <td>White Burgundies From Cote d’Or Set Gold Stand...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[white, burgundies, from, cote, or, set, gold,...</td>\n",
       "      <td>[805, 70870, 29, 18680, 946, 225, 195, 825]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288195</th>\n",
       "      <td>288195</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:00:01-05:00</td>\n",
       "      <td>Chelsea Ties 0-0 Against Man. City as Fans Jee...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[chelsea, ties, against, man, city, as, fans, ...</td>\n",
       "      <td>[1819, 1097, 160, 868, 472, 6, 2494, 36137, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288196</th>\n",
       "      <td>288196</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>Britons’ Spending Power Stagnated in October o...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[britons, spending, power, stagnated, in, octo...</td>\n",
       "      <td>[6566, 283, 157, 19088, 2, 467, 3, 208, 2562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288197</th>\n",
       "      <td>288197</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>U.K. Business Investment Seen at Pace Damping ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[business, investment, seen, at, pace, damping...</td>\n",
       "      <td>[169, 212, 132, 17, 807, 13353, 146, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288198</th>\n",
       "      <td>288198</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>Colombia Bank Votes 4-3 for Rate Cut After Bro...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[colombia, bank, votes, for, rate, cut, after,...</td>\n",
       "      <td>[927, 18, 1624, 5, 72, 59, 12, 1919, 70871]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288199</th>\n",
       "      <td>288199</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>U.K. Energy Policy Weighs on Green Investment:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[energy, policy, weighs, on, green, investment...</td>\n",
       "      <td>[143, 295, 1065, 3, 1055, 212, 1371, 9, 55, 68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288200</th>\n",
       "      <td>288200</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:00-05:00</td>\n",
       "      <td>Osborne May Extend U.K. Austerity to 2018, IFS...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[osborne, may, extend, austerity, to, ifs, says]</td>\n",
       "      <td>[2030, 11, 560, 784, 1, 17593, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288201</th>\n",
       "      <td>288201</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:01:03-05:00</td>\n",
       "      <td>Overnight Rates Surge in Fed’s Operation Twist.</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[overnight, rates, surge, in, fed, operation, ...</td>\n",
       "      <td>[894, 171, 425, 2, 63, 2811, 4286]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288202</th>\n",
       "      <td>288202</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 19:53:16-05:00</td>\n",
       "      <td>Japan Copper-Alloy Product Output Climbs 0.5% ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[japan, copper, alloy, product, output, climbs...</td>\n",
       "      <td>[100, 267, 9887, 1759, 173, 300, 2, 467]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288203</th>\n",
       "      <td>288203</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 20:08:21-05:00</td>\n",
       "      <td>China Yangtze, Jiangsu Shagang, Nanjing Urban:...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[china, yangtze, jiangsu, shagang, nanjing, ur...</td>\n",
       "      <td>[21, 13236, 25313, 70872, 10120, 4511, 21, 85,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288204</th>\n",
       "      <td>288204</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 20:33:00-05:00</td>\n",
       "      <td>Analysis: \"Caveat emptor\" as foreigners rush t...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[analysis, caveat, emptor, as, foreigners, rus...</td>\n",
       "      <td>[177, 30623, 41685, 6, 3806, 2583, 1, 4047, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288205</th>\n",
       "      <td>288205</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 20:49:56-05:00</td>\n",
       "      <td>Notre Dame Remains No. 1 Team in College Footb...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[notre, dame, remains, no, team, in, college, ...</td>\n",
       "      <td>[6417, 6646, 1808, 120, 752, 2, 1951, 2240, 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288206</th>\n",
       "      <td>288206</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 21:00:09-05:00</td>\n",
       "      <td>Stones Roll Back Years, Rock Cheap Seats, No W...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[stones, roll, back, years, rock, cheap, seats...</td>\n",
       "      <td>[14832, 4123, 239, 191, 2035, 2429, 2971, 120,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288207</th>\n",
       "      <td>288207</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 21:01:00-05:00</td>\n",
       "      <td>Sebastian Vettel Wins Third Straight Formula O...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[sebastian, vettel, wins, third, straight, for...</td>\n",
       "      <td>[18584, 6785, 166, 170, 1035, 2758, 243, 4579,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288208</th>\n",
       "      <td>288208</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 22:30:46-05:00</td>\n",
       "      <td>Thermal Coal Swaps for Indonesia Rise; China C...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[thermal, coal, swaps, for, indonesia, rise, c...</td>\n",
       "      <td>[4919, 404, 446, 5, 751, 13, 21, 893, 837]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288209</th>\n",
       "      <td>288209</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 22:45:00-05:00</td>\n",
       "      <td>Qatar cashes in on remaining Barclays warrants.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>0</td>\n",
       "      <td>[qatar, cashes, in, on, remaining, barclays, w...</td>\n",
       "      <td>[854, 15368, 2, 3, 4568, 457, 5311]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288210</th>\n",
       "      <td>288210</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 22:50:55-05:00</td>\n",
       "      <td>China Cosco and ICICI Bank Market Debt; Asia B...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[china, cosco, and, icici, bank, market, debt,...</td>\n",
       "      <td>[21, 5863, 47, 5883, 18, 52, 35, 204, 85, 124,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288211</th>\n",
       "      <td>288211</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:31:17-05:00</td>\n",
       "      <td>Giants Beat Packers 38-10 to End Two-Game NFL ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[giants, beat, packers, to, end, two, game, nf...</td>\n",
       "      <td>[1474, 421, 5402, 1, 184, 93, 698, 1111, 1091,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288212</th>\n",
       "      <td>288212</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:45:15-05:00</td>\n",
       "      <td>Hong Kong Short Selling Turnover Recorded 11/2...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[hong, kong, short, selling, turnover, recorded]</td>\n",
       "      <td>[244, 261, 374, 427, 1047, 1073]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288213</th>\n",
       "      <td>288213</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:47:46-05:00</td>\n",
       "      <td>China Avic Avionics Rises as Jet Lands Success...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[china, avic, avionics, rises, as, jet, lands,...</td>\n",
       "      <td>[21, 21950, 70873, 38, 6, 1316, 4322, 22196, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288214</th>\n",
       "      <td>288214</td>\n",
       "      <td>2012-11-23 00:00:00-05:00</td>\n",
       "      <td>2012-11-25 23:49:23-05:00</td>\n",
       "      <td>Glencore, Vedanta Face Up to 50% Pay-Raise Dem...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>0</td>\n",
       "      <td>[glencore, vedanta, face, up, to, pay, raise, ...</td>\n",
       "      <td>[1445, 4902, 330, 39, 1, 151, 249, 75, 2, 4298]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288215 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                      Date                  datetime  \\\n",
       "0            0 2006-10-20 00:00:00-04:00 2006-10-20 16:16:16-04:00   \n",
       "1            1 2006-10-20 00:00:00-04:00 2006-10-20 16:25:00-04:00   \n",
       "2            2 2006-10-20 00:00:00-04:00 2006-10-20 18:15:00-04:00   \n",
       "3            3 2006-10-20 00:00:00-04:00 2006-10-20 20:08:44-04:00   \n",
       "4            4 2006-10-20 00:00:00-04:00 2006-10-21 14:21:00-04:00   \n",
       "5            5 2006-10-20 00:00:00-04:00 2006-10-21 20:11:00-04:00   \n",
       "6            6 2006-10-20 00:00:00-04:00 2006-10-22 06:46:00-04:00   \n",
       "7            7 2006-10-20 00:00:00-04:00 2006-10-22 12:14:00-04:00   \n",
       "8            8 2006-10-20 00:00:00-04:00 2006-10-22 20:36:00-04:00   \n",
       "9            9 2006-10-20 00:00:00-04:00 2006-10-22 21:51:00-04:00   \n",
       "10          10 2006-10-23 00:00:00-04:00 2006-10-23 01:50:00-04:00   \n",
       "11          11 2006-10-23 00:00:00-04:00 2006-10-23 03:47:00-04:00   \n",
       "12          12 2006-10-23 00:00:00-04:00 2006-10-23 03:51:00-04:00   \n",
       "13          13 2006-10-23 00:00:00-04:00 2006-10-23 05:24:00-04:00   \n",
       "14          14 2006-10-23 00:00:00-04:00 2006-10-23 07:51:36-04:00   \n",
       "15          15 2006-10-23 00:00:00-04:00 2006-10-23 08:36:00-04:00   \n",
       "16          16 2006-10-23 00:00:00-04:00 2006-10-23 09:58:00-04:00   \n",
       "17          17 2006-10-23 00:00:00-04:00 2006-10-23 10:47:00-04:00   \n",
       "18          18 2006-10-23 00:00:00-04:00 2006-10-23 10:49:00-04:00   \n",
       "19          19 2006-10-23 00:00:00-04:00 2006-10-23 10:56:00-04:00   \n",
       "20          20 2006-10-23 00:00:00-04:00 2006-10-23 11:18:00-04:00   \n",
       "21          21 2006-10-23 00:00:00-04:00 2006-10-23 11:20:00-04:00   \n",
       "22          22 2006-10-23 00:00:00-04:00 2006-10-23 11:41:00-04:00   \n",
       "23          23 2006-10-23 00:00:00-04:00 2006-10-23 11:48:00-04:00   \n",
       "24          24 2006-10-23 00:00:00-04:00 2006-10-23 11:52:00-04:00   \n",
       "25          25 2006-10-23 00:00:00-04:00 2006-10-23 12:34:00-04:00   \n",
       "26          26 2006-10-23 00:00:00-04:00 2006-10-23 14:10:00-04:00   \n",
       "27          27 2006-10-23 00:00:00-04:00 2006-10-23 15:06:00-04:00   \n",
       "28          28 2006-10-23 00:00:00-04:00 2006-10-23 15:40:00-04:00   \n",
       "29          29 2006-10-23 00:00:00-04:00 2006-10-23 15:48:00-04:00   \n",
       "...        ...                       ...                       ...   \n",
       "288185  288185 2012-11-23 00:00:00-05:00 2012-11-25 18:25:00-05:00   \n",
       "288186  288186 2012-11-23 00:00:00-05:00 2012-11-25 18:30:16-05:00   \n",
       "288187  288187 2012-11-23 00:00:00-05:00 2012-11-25 18:30:17-05:00   \n",
       "288188  288188 2012-11-23 00:00:00-05:00 2012-11-25 18:30:36-05:00   \n",
       "288189  288189 2012-11-23 00:00:00-05:00 2012-11-25 18:30:58-05:00   \n",
       "288190  288190 2012-11-23 00:00:00-05:00 2012-11-25 18:44:00-05:00   \n",
       "288191  288191 2012-11-23 00:00:00-05:00 2012-11-25 18:45:00-05:00   \n",
       "288192  288192 2012-11-23 00:00:00-05:00 2012-11-25 18:52:54-05:00   \n",
       "288193  288193 2012-11-23 00:00:00-05:00 2012-11-25 19:00:01-05:00   \n",
       "288194  288194 2012-11-23 00:00:00-05:00 2012-11-25 19:00:01-05:00   \n",
       "288195  288195 2012-11-23 00:00:00-05:00 2012-11-25 19:00:01-05:00   \n",
       "288196  288196 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288197  288197 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288198  288198 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288199  288199 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288200  288200 2012-11-23 00:00:00-05:00 2012-11-25 19:01:00-05:00   \n",
       "288201  288201 2012-11-23 00:00:00-05:00 2012-11-25 19:01:03-05:00   \n",
       "288202  288202 2012-11-23 00:00:00-05:00 2012-11-25 19:53:16-05:00   \n",
       "288203  288203 2012-11-23 00:00:00-05:00 2012-11-25 20:08:21-05:00   \n",
       "288204  288204 2012-11-23 00:00:00-05:00 2012-11-25 20:33:00-05:00   \n",
       "288205  288205 2012-11-23 00:00:00-05:00 2012-11-25 20:49:56-05:00   \n",
       "288206  288206 2012-11-23 00:00:00-05:00 2012-11-25 21:00:09-05:00   \n",
       "288207  288207 2012-11-23 00:00:00-05:00 2012-11-25 21:01:00-05:00   \n",
       "288208  288208 2012-11-23 00:00:00-05:00 2012-11-25 22:30:46-05:00   \n",
       "288209  288209 2012-11-23 00:00:00-05:00 2012-11-25 22:45:00-05:00   \n",
       "288210  288210 2012-11-23 00:00:00-05:00 2012-11-25 22:50:55-05:00   \n",
       "288211  288211 2012-11-23 00:00:00-05:00 2012-11-25 23:31:17-05:00   \n",
       "288212  288212 2012-11-23 00:00:00-05:00 2012-11-25 23:45:15-05:00   \n",
       "288213  288213 2012-11-23 00:00:00-05:00 2012-11-25 23:47:46-05:00   \n",
       "288214  288214 2012-11-23 00:00:00-05:00 2012-11-25 23:49:23-05:00   \n",
       "\n",
       "                                               news_title     source  stock  \\\n",
       "0       Inco's Net Soars on Higher Metal Prices, Break...  Bloomberg      1   \n",
       "1       Hey buddy, can you spare $600 for a Google sha...    Reuters      1   \n",
       "2          Exxon Mobil offers plan to end Alaska dispute.    Reuters      1   \n",
       "3       Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...  Bloomberg      1   \n",
       "4       AOL CEO says sales may shrink for two years -p...    Reuters      1   \n",
       "5       Pluspetrol says losing $2.4 mln/day in Peru pr...    Reuters      1   \n",
       "6               EU to urge China to open economy further.    Reuters      1   \n",
       "7            Fed to keep hawkish tone, hold rates steady.    Reuters      1   \n",
       "8                    Weatherford profit jumps 78 percent.    Reuters      1   \n",
       "9       Saudi Arabia tells Japan to cut its Nov crude ...    Reuters      1   \n",
       "10        Australia's Foster's says confident on targets.    Reuters      1   \n",
       "11      Macquarie bids $1.4 bln for metering firm Techem.    Reuters      1   \n",
       "12      DaimlerChrysler talks to 2 firms on small car:...    Reuters      1   \n",
       "13              More solid earnings may keep rally going.    Reuters      1   \n",
       "14      EU Energy Chief Backs German Plan for Price Co...  Bloomberg      1   \n",
       "15      U.S. venture investors betting on energy, Web ...    Reuters      1   \n",
       "16        Shell Canada jumps 30 pct on Royal Dutch offer.    Reuters      1   \n",
       "17            Kimberly-Clark sees higher costs this year.    Reuters      1   \n",
       "18                           Ford won't sell Ford Credit.    Reuters      1   \n",
       "19            Ford sees fourth quarter weaker than third.    Reuters      1   \n",
       "20                      Hasbro profit beats expectations.    Reuters      1   \n",
       "21                   Merrill Lynch to buy Petrie Parkman.    Reuters      1   \n",
       "22         Ford CEO: Jury out on European premium brands.    Reuters      1   \n",
       "23            Kimberly-Clark profit higher, narrows view.    Reuters      1   \n",
       "24      Wal-Mart October sales growth tracking below f...    Reuters      1   \n",
       "25      Bombardier could launch new jet this year: ana...    Reuters      1   \n",
       "26      Private equity groups form for Tribune bid: so...    Reuters      1   \n",
       "27                       AT&T earnings beat expectations.    Reuters      1   \n",
       "28       Wrigley sees no change in communications policy.    Reuters      1   \n",
       "29           Ford is reviewing all products, brands: CEO.    Reuters      1   \n",
       "...                                                   ...        ...    ...   \n",
       "288185      Mexico \"Buen Fin\" sales up by nearly a third.    Reuters      0   \n",
       "288186   Fed’s Dudley Signals a Shift Toward Bank Reform.  Bloomberg      0   \n",
       "288187  Natural-Gas Exports Could Lift U.S. Trade and ...  Bloomberg      0   \n",
       "288188  Spain’s Bad Bank Needs Goodwill From Europe’s ...  Bloomberg      0   \n",
       "288189   Regulate U.S. Markets Like the Nuclear Industry.  Bloomberg      0   \n",
       "288190  Black Friday sales online top $1 billion for f...    Reuters      0   \n",
       "288191  Apple seeks to add more products to Samsung pa...    Reuters      0   \n",
       "288192  Qantas Minds Bonds as Dreamliner Order Pulled:...  Bloomberg      0   \n",
       "288193  BBC’s Chief Honed Skills Saving Covent Garden:...  Bloomberg      0   \n",
       "288194  White Burgundies From Cote d’Or Set Gold Stand...  Bloomberg      0   \n",
       "288195  Chelsea Ties 0-0 Against Man. City as Fans Jee...  Bloomberg      0   \n",
       "288196  Britons’ Spending Power Stagnated in October o...  Bloomberg      0   \n",
       "288197  U.K. Business Investment Seen at Pace Damping ...  Bloomberg      0   \n",
       "288198  Colombia Bank Votes 4-3 for Rate Cut After Bro...  Bloomberg      0   \n",
       "288199  U.K. Energy Policy Weighs on Green Investment:...  Bloomberg      0   \n",
       "288200  Osborne May Extend U.K. Austerity to 2018, IFS...  Bloomberg      0   \n",
       "288201    Overnight Rates Surge in Fed’s Operation Twist.  Bloomberg      0   \n",
       "288202  Japan Copper-Alloy Product Output Climbs 0.5% ...  Bloomberg      0   \n",
       "288203  China Yangtze, Jiangsu Shagang, Nanjing Urban:...  Bloomberg      0   \n",
       "288204  Analysis: \"Caveat emptor\" as foreigners rush t...    Reuters      0   \n",
       "288205  Notre Dame Remains No. 1 Team in College Footb...  Bloomberg      0   \n",
       "288206  Stones Roll Back Years, Rock Cheap Seats, No W...  Bloomberg      0   \n",
       "288207  Sebastian Vettel Wins Third Straight Formula O...  Bloomberg      0   \n",
       "288208  Thermal Coal Swaps for Indonesia Rise; China C...  Bloomberg      0   \n",
       "288209    Qatar cashes in on remaining Barclays warrants.    Reuters      0   \n",
       "288210  China Cosco and ICICI Bank Market Debt; Asia B...  Bloomberg      0   \n",
       "288211  Giants Beat Packers 38-10 to End Two-Game NFL ...  Bloomberg      0   \n",
       "288212  Hong Kong Short Selling Turnover Recorded 11/2...  Bloomberg      0   \n",
       "288213  China Avic Avionics Rises as Jet Lands Success...  Bloomberg      0   \n",
       "288214  Glencore, Vedanta Face Up to 50% Pay-Raise Dem...  Bloomberg      0   \n",
       "\n",
       "                                                    words  \\\n",
       "0       [inco, net, soars, on, higher, metal, prices, ...   \n",
       "1       [hey, buddy, can, you, spare, for, google, share]   \n",
       "2       [exxon, mobil, offers, plan, to, end, alaska, ...   \n",
       "3       [jim, cramer, diageo, anheuser, busch, monster...   \n",
       "4       [aol, ceo, says, sales, may, shrink, for, two,...   \n",
       "5       [pluspetrol, says, losing, mln, day, in, peru,...   \n",
       "6       [eu, to, urge, china, to, open, economy, further]   \n",
       "7       [fed, to, keep, hawkish, tone, hold, rates, st...   \n",
       "8                   [weatherford, profit, jumps, percent]   \n",
       "9       [saudi, arabia, tells, japan, to, cut, its, no...   \n",
       "10      [australia, foster, says, confident, on, targets]   \n",
       "11      [macquarie, bids, bln, for, metering, firm, te...   \n",
       "12      [daimlerchrysler, talks, to, firms, on, small,...   \n",
       "13       [more, solid, earnings, may, keep, rally, going]   \n",
       "14      [eu, energy, chief, backs, german, plan, for, ...   \n",
       "15         [venture, investors, betting, on, energy, web]   \n",
       "16      [shell, canada, jumps, pct, on, royal, dutch, ...   \n",
       "17      [kimberly, clark, sees, higher, costs, this, y...   \n",
       "18                        [ford, won, sell, ford, credit]   \n",
       "19      [ford, sees, fourth, quarter, weaker, than, th...   \n",
       "20                  [hasbro, profit, beats, expectations]   \n",
       "21             [merrill, lynch, to, buy, petrie, parkman]   \n",
       "22      [ford, ceo, jury, out, on, european, premium, ...   \n",
       "23       [kimberly, clark, profit, higher, narrows, view]   \n",
       "24      [wal, mart, october, sales, growth, tracking, ...   \n",
       "25      [bombardier, could, launch, new, jet, this, ye...   \n",
       "26      [private, equity, groups, form, for, tribune, ...   \n",
       "27                     [at, earnings, beat, expectations]   \n",
       "28      [wrigley, sees, no, change, in, communications...   \n",
       "29      [ford, is, reviewing, all, products, brands, ceo]   \n",
       "...                                                   ...   \n",
       "288185  [mexico, buen, fin, sales, up, by, nearly, third]   \n",
       "288186  [fed, dudley, signals, shift, toward, bank, re...   \n",
       "288187  [natural, gas, exports, could, lift, trade, an...   \n",
       "288188  [spain, bad, bank, needs, goodwill, from, euro...   \n",
       "288189  [regulate, markets, like, the, nuclear, industry]   \n",
       "288190  [black, friday, sales, online, top, billion, f...   \n",
       "288191  [apple, seeks, to, add, more, products, to, sa...   \n",
       "288192  [qantas, minds, bonds, as, dreamliner, order, ...   \n",
       "288193  [bbc, chief, honed, skills, saving, covent, ga...   \n",
       "288194  [white, burgundies, from, cote, or, set, gold,...   \n",
       "288195  [chelsea, ties, against, man, city, as, fans, ...   \n",
       "288196  [britons, spending, power, stagnated, in, octo...   \n",
       "288197  [business, investment, seen, at, pace, damping...   \n",
       "288198  [colombia, bank, votes, for, rate, cut, after,...   \n",
       "288199  [energy, policy, weighs, on, green, investment...   \n",
       "288200   [osborne, may, extend, austerity, to, ifs, says]   \n",
       "288201  [overnight, rates, surge, in, fed, operation, ...   \n",
       "288202  [japan, copper, alloy, product, output, climbs...   \n",
       "288203  [china, yangtze, jiangsu, shagang, nanjing, ur...   \n",
       "288204  [analysis, caveat, emptor, as, foreigners, rus...   \n",
       "288205  [notre, dame, remains, no, team, in, college, ...   \n",
       "288206  [stones, roll, back, years, rock, cheap, seats...   \n",
       "288207  [sebastian, vettel, wins, third, straight, for...   \n",
       "288208  [thermal, coal, swaps, for, indonesia, rise, c...   \n",
       "288209  [qatar, cashes, in, on, remaining, barclays, w...   \n",
       "288210  [china, cosco, and, icici, bank, market, debt,...   \n",
       "288211  [giants, beat, packers, to, end, two, game, nf...   \n",
       "288212   [hong, kong, short, selling, turnover, recorded]   \n",
       "288213  [china, avic, avionics, rises, as, jet, lands,...   \n",
       "288214  [glencore, vedanta, face, up, to, pay, raise, ...   \n",
       "\n",
       "                                               embeddings  \n",
       "0        [14411, 222, 1237, 3, 172, 1541, 53, 3018, 1404]  \n",
       "1            [12905, 17975, 440, 2332, 6801, 5, 318, 246]  \n",
       "2                [1044, 4648, 449, 56, 1, 184, 3089, 788]  \n",
       "3        [4543, 24198, 5067, 3019, 3686, 3519, 3090, 318]  \n",
       "4            [2528, 49, 4, 10, 11, 2031, 5, 93, 191, 666]  \n",
       "5                [24199, 4, 1091, 1165, 68, 2, 847, 1336]  \n",
       "6                      [80, 1, 1657, 21, 1, 257, 73, 873]  \n",
       "7                [63, 1, 487, 15302, 5407, 492, 171, 851]  \n",
       "8                                   [12258, 27, 310, 121]  \n",
       "9       [398, 1571, 406, 100, 1, 59, 256, 2052, 207, 276]  \n",
       "10                           [292, 7573, 4, 1696, 3, 513]  \n",
       "11                 [2695, 683, 609, 5, 14408, 568, 41688]  \n",
       "12                   [6079, 86, 1, 519, 3, 806, 539, 666]  \n",
       "13                    [43, 3068, 148, 11, 487, 185, 3149]  \n",
       "14             [80, 143, 153, 713, 122, 56, 5, 125, 1968]  \n",
       "15                         [659, 145, 3926, 3, 143, 1200]  \n",
       "16               [848, 234, 310, 754, 3, 2032, 1321, 205]  \n",
       "17                    [6311, 4037, 54, 172, 183, 215, 28]  \n",
       "18                              [416, 1036, 107, 416, 62]  \n",
       "19                     [416, 54, 403, 87, 1192, 112, 170]  \n",
       "20                                   [5408, 27, 213, 912]  \n",
       "21                       [801, 2861, 1, 70, 32331, 41689]  \n",
       "22               [416, 49, 1645, 214, 3, 111, 1201, 1612]  \n",
       "23                        [6311, 4037, 27, 172, 987, 106]  \n",
       "24                [534, 551, 467, 10, 34, 3989, 704, 110]  \n",
       "25              [3540, 274, 1364, 26, 1316, 215, 28, 744]  \n",
       "26               [465, 139, 1741, 1924, 5, 1405, 92, 314]  \n",
       "27                                    [17, 148, 421, 912]  \n",
       "28                    [10035, 54, 120, 635, 2, 2910, 295]  \n",
       "29                    [416, 66, 3601, 584, 909, 1612, 49]  \n",
       "...                                                   ...  \n",
       "288185          [392, 41686, 5615, 10, 39, 22, 2163, 170]  \n",
       "288186               [63, 2722, 791, 1271, 1389, 18, 642]  \n",
       "288187            [511, 127, 248, 274, 1098, 179, 47, 73]  \n",
       "288188             [199, 901, 18, 466, 9488, 29, 84, 667]  \n",
       "288189                    [7094, 144, 1530, 55, 488, 491]  \n",
       "288190   [1104, 1947, 10, 907, 174, 16, 5, 48, 190, 8253]  \n",
       "288191      [236, 103, 1, 749, 43, 909, 1, 670, 887, 612]  \n",
       "288192      [1832, 8037, 57, 6, 3692, 651, 5218, 292, 62]  \n",
       "288193  [3311, 153, 35376, 6688, 3894, 21973, 6546, 9535]  \n",
       "288194        [805, 70870, 29, 18680, 946, 225, 195, 825]  \n",
       "288195  [1819, 1097, 160, 868, 472, 6, 2494, 36137, 12...  \n",
       "288196      [6566, 283, 157, 19088, 2, 467, 3, 208, 2562]  \n",
       "288197           [169, 212, 132, 17, 807, 13353, 146, 34]  \n",
       "288198        [927, 18, 1624, 5, 72, 59, 12, 1919, 70871]  \n",
       "288199    [143, 295, 1065, 3, 1055, 212, 1371, 9, 55, 68]  \n",
       "288200                  [2030, 11, 560, 784, 1, 17593, 4]  \n",
       "288201                 [894, 171, 425, 2, 63, 2811, 4286]  \n",
       "288202           [100, 267, 9887, 1759, 173, 300, 2, 467]  \n",
       "288203  [21, 13236, 25313, 70872, 10120, 4511, 21, 85,...  \n",
       "288204  [177, 30623, 41685, 6, 3806, 2583, 1, 4047, 21...  \n",
       "288205  [6417, 6646, 1808, 120, 752, 2, 1951, 2240, 85...  \n",
       "288206  [14832, 4123, 239, 191, 2035, 2429, 2971, 120,...  \n",
       "288207  [18584, 6785, 166, 170, 1035, 2758, 243, 4579,...  \n",
       "288208         [4919, 404, 446, 5, 751, 13, 21, 893, 837]  \n",
       "288209                [854, 15368, 2, 3, 4568, 457, 5311]  \n",
       "288210  [21, 5863, 47, 5883, 18, 52, 35, 204, 85, 124,...  \n",
       "288211  [1474, 421, 5402, 1, 184, 93, 698, 1111, 1091,...  \n",
       "288212                   [244, 261, 374, 427, 1047, 1073]  \n",
       "288213  [21, 21950, 70873, 38, 6, 1316, 4322, 22196, 3...  \n",
       "288214    [1445, 4902, 330, 39, 1, 151, 249, 75, 2, 4298]  \n",
       "\n",
       "[288215 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['embeddings'] = [np.squeeze(x) for x in np.split(train_embed, train_embed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['embeddings'] = [embedding_matrix[x] for x in train_df['embeddings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:, ['news_title']] = test_df.loc[:, ['news_title']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "test_df['words'] = test_df.news_title.map(simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to sequence\n",
    "test_df['embeddings'] = t.texts_to_sequences(test_df['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "test_embed = pad_sequences(test_df['embeddings'], maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['embeddings'] = [np.squeeze(x) for x in np.split(test_embed, test_embed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['embeddings'] = [embedding_matrix[x] for x in test_df['embeddings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate events by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['stock'] = train_df['stock'].astype(int)\n",
    "test_df['stock'] = test_df['stock'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>news_title</th>\n",
       "      <th>source</th>\n",
       "      <th>stock</th>\n",
       "      <th>words</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:16:16-04:00</td>\n",
       "      <td>Inco's Net Soars on Higher Metal Prices, Break...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[inco, net, soars, on, higher, metal, prices, ...</td>\n",
       "      <td>[[0.45153000950813293, 1.2962000370025635, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 16:25:00-04:00</td>\n",
       "      <td>Hey buddy, can you spare $600 for a Google sha...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, buddy, can, you, spare, for, google, share]</td>\n",
       "      <td>[[0.37766000628471375, 0.42607998847961426, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 18:15:00-04:00</td>\n",
       "      <td>Exxon Mobil offers plan to end Alaska dispute.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[exxon, mobil, offers, plan, to, end, alaska, ...</td>\n",
       "      <td>[[1.0338000059127808, 0.4104999899864197, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-20 20:08:44-04:00</td>\n",
       "      <td>Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>1</td>\n",
       "      <td>[jim, cramer, diageo, anheuser, busch, monster...</td>\n",
       "      <td>[[-0.5946000218391418, 0.24015000462532043, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>2006-10-21 14:21:00-04:00</td>\n",
       "      <td>AOL CEO says sales may shrink for two years -p...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[aol, ceo, says, sales, may, shrink, for, two,...</td>\n",
       "      <td>[[0.2813799977302551, -0.5907800197601318, 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                      Date                  datetime  \\\n",
       "0      0 2006-10-20 00:00:00-04:00 2006-10-20 16:16:16-04:00   \n",
       "1      1 2006-10-20 00:00:00-04:00 2006-10-20 16:25:00-04:00   \n",
       "2      2 2006-10-20 00:00:00-04:00 2006-10-20 18:15:00-04:00   \n",
       "3      3 2006-10-20 00:00:00-04:00 2006-10-20 20:08:44-04:00   \n",
       "4      4 2006-10-20 00:00:00-04:00 2006-10-21 14:21:00-04:00   \n",
       "\n",
       "                                          news_title     source  stock  \\\n",
       "0  Inco's Net Soars on Higher Metal Prices, Break...  Bloomberg      1   \n",
       "1  Hey buddy, can you spare $600 for a Google sha...    Reuters      1   \n",
       "2     Exxon Mobil offers plan to end Alaska dispute.    Reuters      1   \n",
       "3  Jim Cramer: Diageo, Anheuser-Busch, Monster Wo...  Bloomberg      1   \n",
       "4  AOL CEO says sales may shrink for two years -p...    Reuters      1   \n",
       "\n",
       "                                               words  \\\n",
       "0  [inco, net, soars, on, higher, metal, prices, ...   \n",
       "1  [hey, buddy, can, you, spare, for, google, share]   \n",
       "2  [exxon, mobil, offers, plan, to, end, alaska, ...   \n",
       "3  [jim, cramer, diageo, anheuser, busch, monster...   \n",
       "4  [aol, ceo, says, sales, may, shrink, for, two,...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[0.45153000950813293, 1.2962000370025635, -0....  \n",
       "1  [[0.37766000628471375, 0.42607998847961426, 1....  \n",
       "2  [[1.0338000059127808, 0.4104999899864197, 0.09...  \n",
       "3  [[-0.5946000218391418, 0.24015000462532043, 0....  \n",
       "4  [[0.2813799977302551, -0.5907800197601318, 0.4...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = train_df.groupby('Date')\n",
    "\n",
    "agg_train_df = pd.concat([g.embeddings.apply(np.mean, axis=0),\n",
    "                          g.stock.apply(np.mean, axis=0)\n",
    "                         ],\n",
    "                         axis=1)\n",
    "\n",
    "agg_train_df.reset_index(inplace=True)\n",
    "\n",
    "agg_train_df.to_pickle('agg_train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = test_df.groupby('Date')\n",
    "\n",
    "agg_test_df = pd.concat([g.embeddings.apply(np.mean, axis=0),\n",
    "                          g.stock.apply(np.mean, axis=0)\n",
    "                         ],\n",
    "                         axis=1)\n",
    "\n",
    "agg_test_df.reset_index(inplace=True)\n",
    "\n",
    "agg_test_df.to_pickle('agg_test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train_df = pd.read_pickle('agg_train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_test_df = pd.read_pickle('agg_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-10-20 00:00:00-04:00</td>\n",
       "      <td>[[0.15673499777913094, 0.1809510998427868, 0.4...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-10-23 00:00:00-04:00</td>\n",
       "      <td>[[-0.0007124438293670353, 0.062406974550532665...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-10-24 00:00:00-04:00</td>\n",
       "      <td>[[0.20981161274248733, 0.13421877161599696, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-10-25 00:00:00-04:00</td>\n",
       "      <td>[[0.21190344616479706, 0.13870281755225733, 0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-10-26 00:00:00-04:00</td>\n",
       "      <td>[[0.2520672485232353, 0.06778985364362597, 0.3...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0 2006-10-20 00:00:00-04:00   \n",
       "1 2006-10-23 00:00:00-04:00   \n",
       "2 2006-10-24 00:00:00-04:00   \n",
       "3 2006-10-25 00:00:00-04:00   \n",
       "4 2006-10-26 00:00:00-04:00   \n",
       "\n",
       "                                          embeddings  stock  \n",
       "0  [[0.15673499777913094, 0.1809510998427868, 0.4...    1.0  \n",
       "1  [[-0.0007124438293670353, 0.062406974550532665...    1.0  \n",
       "2  [[0.20981161274248733, 0.13421877161599696, 0....    1.0  \n",
       "3  [[0.21190344616479706, 0.13870281755225733, 0....    1.0  \n",
       "4  [[0.2520672485232353, 0.06778985364362597, 0.3...    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back from series of arrays to large array of (events, maxlen, embedding_dims)\n",
    "x_train = np.array(agg_train_df.embeddings.to_list())\n",
    "y_train = np.array(agg_train_df.stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back from series of arrays to large array of (events, maxlen, embedding_dims)\n",
    "x_test = np.array(agg_test_df.embeddings.to_list())\n",
    "y_test = np.array(agg_test_df.stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l2_penalty = 0.0000001\n",
    "l2_penalty = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take real inputs\n",
    "event_in_ = Input(shape=(None, maxlen, embedding_dim), dtype='float32', name='x_train')\n",
    "\n",
    "# # Average embeddings for o1, p, o2\n",
    "average = keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=2))\n",
    "event_ = average(event_in_) # Output dim (100)\n",
    "\n",
    "\n",
    "# Hidden layer\n",
    "hidden1_ = keras.layers.Dense(units=100, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(event_)\n",
    "\n",
    "# event_day_ = Conv1D(filters=embedding_dim, kernel_size=1, strides=1, padding='same', activation='relu',\n",
    "#                     use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "#                    )(hidden1_)\n",
    "\n",
    "event_week_ = Conv1D(filters=embedding_dim, kernel_size=5, strides=1, padding='causal', activation='relu',\n",
    "                     use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                    )(hidden1_)\n",
    "\n",
    "event_month_ = Conv1D(filters=embedding_dim, kernel_size=20, strides=1, padding='causal', activation='relu',\n",
    "                      use_bias=True, kernel_regularizer=l2(l2_penalty), bias_regularizer=l2(l2_penalty)\n",
    "                     )(hidden1_)\n",
    "\n",
    "\n",
    "# # Max pooling of weekly and monthly events\n",
    "max_pool_week_ = MaxPooling1D(pool_size=3, strides=1, padding='same', data_format='channels_last'\n",
    "                              )(event_week_)\n",
    "\n",
    "max_pool_month_ = MaxPooling1D(pool_size=3, strides=1, padding='same', data_format='channels_last'\n",
    "                              )(event_month_)\n",
    "\n",
    "# # Concatenate daily, weekly, monthly\n",
    "concat_ = keras.layers.Concatenate(axis=2)([hidden1_, event_week_, event_month_])\n",
    "\n",
    "# Hidden layer\n",
    "hidden2_ = keras.layers.Dense(units=50, activation='relu', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(concat_)\n",
    "\n",
    "# Softmax layer\n",
    "y_pred_ = keras.layers.Dense(units=1, activation='sigmoid', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(hidden2_)\n",
    "\n",
    "cnn_model = Model(inputs=event_in_, outputs=y_pred_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.001, clipvalue=0.5)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6931 - acc: 0.5130\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6931 - acc: 0.5261\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6931 - acc: 0.5385\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6930 - acc: 0.5424\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6930 - acc: 0.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1877a3780>"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(x=np.expand_dims(x_train, 0),\n",
    "          y=np.expand_dims(np.expand_dims(y_train, -1), 0), \n",
    "          batch_size=200, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = cnn_model.predict(x=np.expand_dims(x_test, 0), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148,   0],\n",
       "       [104,   1]], dtype=int64)"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred.squeeze() > .5, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, y_pred.squeeze() > .5), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred.squeeze() > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_penalty = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take real inputs\n",
    "event_in_ = Input(shape=(None, maxlen, embedding_dim), dtype='float32', name='x_train')\n",
    "# Average embeddings for o1, p, o2\n",
    "average = keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=2))\n",
    "event_ = average(event_in_) # Output dim (100)\n",
    "\n",
    "# Hidden layer\n",
    "hidden1_ = keras.layers.Dense(units=100, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(event_)\n",
    "\n",
    "\n",
    "# Hidden layer\n",
    "hidden2_ = keras.layers.Dense(units=50, activation='relu', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(hidden1_)\n",
    "\n",
    "# Hidden layer\n",
    "hidden3_ = keras.layers.Dense(units=25, activation='relu', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(hidden2_)\n",
    "\n",
    "# Softmax layer\n",
    "y_pred_ = keras.layers.Dense(units=1, activation='sigmoid', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(hidden3_)\n",
    "\n",
    "model = Model(inputs=event_in_, outputs=y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.6932 - acc: 0.5476\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6931 - acc: 0.5476\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6931 - acc: 0.5476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e194c5e898>"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=np.expand_dims(x_train, 0),\n",
    "          y=np.expand_dims(np.expand_dims(y_train, -1), 0), \n",
    "          batch_size=100, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148,   0],\n",
       "       [105,   0]], dtype=int64)"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x=np.expand_dims(x_test, 0), batch_size=100)\n",
    "confusion_matrix(y_test, y_pred.squeeze() > .5, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_test, y_pred.squeeze() > .5), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-846-615b0aaa81d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lstm_model' is not defined"
     ]
    }
   ],
   "source": [
    "del lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_penalty = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take real inputs\n",
    "event_in_ = Input(shape=(None, maxlen, embedding_dim), dtype='float32', name='x_train')\n",
    "# # Average embeddings for o1, p, o2\n",
    "average = keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=2))\n",
    "event_ = average(event_in_) # Output dim (100)\n",
    "\n",
    "# LSTM layer\n",
    "lstm1_ = keras.layers.LSTM(units=100, return_sequences=True)(event_)\n",
    "#lstm1_ = keras.layers.Dropout(rate = 0.9)(lstm1_)\n",
    "\n",
    "# LSTM layer\n",
    "lstm2_ = keras.layers.LSTM(units=50, return_sequences=True )(lstm1_)\n",
    "#lstm2_ = keras.layers.Dropout(rate = 0.9)(lstm2_)\n",
    "\n",
    "# LSTM layer\n",
    "lstm3_ = keras.layers.LSTM(units=50, return_sequences=True )(lstm1_)\n",
    "#lstm3_ = keras.layers.Dropout(rate = 0.9)(lstm3_)\n",
    "\n",
    "# Dense layer\n",
    "hidden_ = keras.layers.Dense(units=50, activation='relu', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(lstm3_)\n",
    "\n",
    "# Softmax layer\n",
    "y_pred_ = keras.layers.Dense(units=1, activation='sigmoid', use_bias=True, kernel_initializer='normal', \n",
    "                             bias_initializer='zeros', kernel_regularizer=l2(l2_penalty), \n",
    "                             bias_regularizer=l2(l2_penalty),\n",
    "                            )(hidden_)\n",
    "\n",
    "lstm_model = Model(inputs=event_in_, outputs=y_pred_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.001, clipvalue=0.5)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6930 - acc: 0.5476\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6930 - acc: 0.5476\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6930 - acc: 0.5476\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6930 - acc: 0.5476\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6930 - acc: 0.5476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e161ef2080>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(x=np.expand_dims(x_train, 0),\n",
    "          y=np.expand_dims(np.expand_dims(y_train, -1), 0), \n",
    "          batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148,   0],\n",
       "       [105,   0]], dtype=int64)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lstm_model.predict(x=np.expand_dims(x_test, 0), batch_size=100).squeeze()\n",
    "confusion_matrix(y_test, y_pred.squeeze() > .5, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_pred=y_pred>.5, y_true=y_test), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
